{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USE HMM network to inference \n",
    "\n",
    "1. Since max step =2, each room can generate a HMM with neibours room in previous time state and relevant sensors at current and all previous  time stamp.\n",
    "2. we use a binary situation for outcome space {0,1} \n",
    "3. Based on the network, we will learn P(X_1={0/1} | X ={0/1}}, note the state will determine the action directly\n",
    "4. Then we can inference B(X_t) by passage of time and observations Topic 8 from page 28\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Allowed libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scipy.special\n",
    "import heapq as pq\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from itertools import product, combinations\n",
    "from collections import OrderedDict as odict\n",
    "import collections\n",
    "from graphviz import Digraph, Graph\n",
    "from tabulate import tabulate\n",
    "import copy\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import sklearn\n",
    "import ast\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'reliable_sensor1', 'reliable_sensor2',\n",
       "       'reliable_sensor3', 'reliable_sensor4', 'unreliable_sensor1',\n",
       "       'unreliable_sensor2', 'unreliable_sensor3', 'unreliable_sensor4',\n",
       "       'robot1', 'robot2', 'door_sensor1', 'door_sensor2', 'door_sensor3',\n",
       "       'door_sensor4', 'time', 'electricity_price', 'r1', 'r2', 'r3', 'r4',\n",
       "       'r5', 'r6', 'r7', 'r8', 'r9', 'r10', 'r11', 'r12', 'r13', 'r14', 'r15',\n",
       "       'r16', 'r17', 'r18', 'r19', 'r20', 'r21', 'r22', 'r23', 'r24', 'r25',\n",
       "       'r26', 'r27', 'r28', 'r29', 'r30', 'r31', 'r32', 'r33', 'r34', 'r35',\n",
       "       'c1', 'c2', 'c3', 'c4', 'o1', 'outside'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = copy.deepcopy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP = {\n",
    "    \"r1\":[\"r2\",\"r3\"],\n",
    "    \"r2\":[\"r1\",\"r4\"],\n",
    "    \"r3\":[\"r1\",\"r7\"],\n",
    "    \"r4\":[\"r2\",\"r8\"],\n",
    "    \"r5\":[\"r6\",\"r9\",\"c3\"],\n",
    "    \"r6\":[\"r5\",\"c3\"],\n",
    "    \"r7\":[\"r3\",\"c1\"],\n",
    "    \"r8\":[\"r4\",\"r9\"],\n",
    "    \"r9\":[\"r5\",\"r8\",\"r13\"],\n",
    "    \"r10\":[\"c3\"],\n",
    "    \"r11\":[\"c3\"],\n",
    "    \"r12\":[\"outside\",\"r22\"],\n",
    "    \"r13\":[\"r9\",\"r24\"],\n",
    "    \"r14\":[\"r24\"],\n",
    "    \"r15\":[\"c3\"],\n",
    "    \"r16\":[\"c3\"],\n",
    "    \"r17\":[\"c3\"],\n",
    "    \"r18\":[\"c3\"],\n",
    "    \"r19\":[\"c3\"],\n",
    "    \"r20\":[\"c3\"],\n",
    "    \"r21\":[\"c3\"],\n",
    "    \"r22\":[\"r12\",\"r25\"],\n",
    "    \"r23\":[\"r24\"],\n",
    "    \"r24\":[\"r13\",\"r14\",\"r23\"],\n",
    "    \"r25\":[\"r22\",\"r26\",\"c1\"],\n",
    "    \"r26\":[\"r25\",\"r27\"],\n",
    "    \"r27\":[\"r26\",\"r32\"],\n",
    "    \"r28\":[\"c4\"],\n",
    "    \"r29\":[\"c4\",\"r30\"],\n",
    "    \"r30\":[\"r29\"],\n",
    "    \"r31\":[\"r32\"],\n",
    "    \"r32\":[\"r27\",\"r31\",\"r33\"],\n",
    "    \"r33\":[\"r32\"],\n",
    "    \"r34\":[\"c2\"],\n",
    "    \"r35\":[\"c4\"],\n",
    "    \"c1\":[\"r7\",\"r25\",\"c2\"],\n",
    "    \"c2\":[\"c1\",\"r34\",\"c4\"],\n",
    "    \"c3\": [\"r5\",\"r6\",\"r10\",\"r11\",\"r15\",\"r16\",\"r17\",\"r18\",\"r19\",\"r20\",\"r21\",\"o1\"],\n",
    "    \"c4\":[\"r29\",\"c2\",\"r35\",\"r28\",\"o1\"],\n",
    "    \"o1\":[\"c3\",\"c4\"],\n",
    "    \"outside\":[\"r12\"]  \n",
    "}\n",
    "censor_dict =  {\n",
    "    \"r1\": \"us3\", #us for unreliable_sensor\n",
    "    \"r5\": \"rs2\" ,#rs for reliable_sensor\n",
    "    \"r8\": \"ds1\", #ds for door sensor\n",
    "    \"r9\": \"ds1\",\n",
    "    \"r16\": \"rs1\",\n",
    "    \"r24\" : \"us4\",\n",
    "    \"r25\" : \"rs3\",\n",
    "    \"r26\" : \"ds3\", \n",
    "    \"r27\" : \"ds3\",\n",
    "    \"r31\" : \"rs4\",\n",
    "    \"r35\" : \"ds4\",\n",
    "    \"c1\" : \"ds2\",\n",
    "    \"c2\" : \"ds2\",\n",
    "    \"c3\" : \"us2\",\n",
    "    \"c4\" : \"ds4\",\n",
    "    \"o1\" : \"us1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_step_neighbour(node,n,G):\n",
    "    neighbour_list = []\n",
    "    neighbour_list = neighbour_list + G[node]\n",
    "    while n > 1:\n",
    "        for new_node in neighbour_list:\n",
    "            neighbour_list = neighbour_list+ G[new_node]\n",
    "        n = n -1 \n",
    "    n_list = list(set(neighbour_list))\n",
    "    n_list.remove(node)\n",
    "    return(n_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_HMM(node,G,censors):\n",
    "    HMM = {}\n",
    "    curr_node = \"current_\" + node\n",
    "    node_neighbour = n_step_neighbour(node,2,G)\n",
    "    HMM = {i:[curr_node] for i in node_neighbour}\n",
    "    HMM[node] = [curr_node]\n",
    "    \n",
    "    related_censor = [censors.get(node)] + [censors.get(i) for i in node_neighbour]\n",
    "    related_censor = [x for x in related_censor  if x is not None]\n",
    "    \n",
    "    for i in related_censor:\n",
    "        if i[0] ==\"d\":\n",
    "            if sum([censor == i for censor in related_censor]) < 2:\n",
    "                related_censor.remove(i) #drop door censor when you only at one side\n",
    "    \n",
    "    \n",
    "    \n",
    "    HMM[curr_node] = list(set(related_censor))\n",
    "    for censor_evi in related_censor: \n",
    "        HMM[censor_evi] = []\n",
    "    \n",
    "    return(HMM)\n",
    "    \n",
    "    \n",
    "#def learn_prob(G,data):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r27': ['current_r25'],\n",
       " 'r7': ['current_r25'],\n",
       " 'r26': ['current_r25'],\n",
       " 'c1': ['current_r25'],\n",
       " 'r22': ['current_r25'],\n",
       " 'r12': ['current_r25'],\n",
       " 'c2': ['current_r25'],\n",
       " 'r25': ['current_r25'],\n",
       " 'current_r25': ['rs3', 'ds3', 'ds2'],\n",
       " 'rs3': [],\n",
       " 'ds3': [],\n",
       " 'ds2': []}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_HMM('r25',MAP,censor_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_tranisition(curr_node,pre_node,data):\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df['curr'] = data[curr_node][1:]\n",
    "    new_df['pre'] = data[pre_node].shift(1)[:-1]\n",
    "    \n",
    "    \n",
    "    prob_ct = pd.crosstab(new_df['pre'] > 0 , new_df['curr'] > 0, normalize = \"index\")\n",
    "    \n",
    "    tran_table = odict()\n",
    "    \n",
    "    tran_table[(1,1)] = prob_ct.loc[True,True] # p(current = 1 | previous = 1)\n",
    "    tran_table[(1,0)] = prob_ct.loc[True,False]\n",
    "    tran_table[(0,1)] =prob_ct.loc[False,True]# p(current = 1 | previous = 0)\n",
    "    tran_table[(0,0)] =  prob_ct.loc[False,False]\n",
    "    \n",
    "    \n",
    "    return ({'dom': (pre_node,curr_node), 'table':tran_table})\n",
    "\n",
    "def learn_censor_prob(node, censor, data):\n",
    "    \n",
    "    prob_ct = pd.crosstab(data[node] > 0 , data[censor] == \"motion\", normalize = \"index\")\n",
    "    \n",
    "    tran_table = odict()\n",
    "    \n",
    "    tran_table[(1,1)] = prob_ct.loc[True,True] # p(current = 1 | previous = 1)\n",
    "    tran_table[(1,0)] = prob_ct.loc[True,False]\n",
    "    tran_table[(0,1)] =prob_ct.loc[False,True]# p(current = 1 | previous = 0)\n",
    "    tran_table[(0,0)] =  prob_ct.loc[False,False]\n",
    "    \n",
    "    return ({'dom': (node,censor), 'table':tran_table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dom': ('r25', 'r22'),\n",
       " 'table': OrderedDict([((1, 1), 0.10268378063010501),\n",
       "              ((1, 0), 0.897316219369895),\n",
       "              ((0, 1), 0.13933895009721323),\n",
       "              ((0, 0), 0.8606610499027868)])}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_tranisition('r22','r25',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dom': ('r25', 'reliable_sensor3'),\n",
       " 'table': OrderedDict([((1, 1), 0.9568261376896149),\n",
       "              ((1, 0), 0.043173862310385065),\n",
       "              ((0, 1), 0.03367875647668394),\n",
       "              ((0, 0), 0.966321243523316)])}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_censor_prob('r25','reliable_sensor3',data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one room:\n",
    "    1. generate the network \n",
    "    2. Assign the conditional prob (factor tables) \n",
    "    3. Find P(X=1| other nodes, e) and P(X=0| other nodes, e) by HMM algorithm;\n",
    "    4. Make decicions (threshold) \n",
    " \n",
    "Entire inference process: \n",
    "    1. calculate all the probabilities \n",
    "    2. For t = 1, ... T: \n",
    "        a. Do inference for each room\n",
    "        b. Store the decision \n",
    "        c. move to next timestep \n",
    "             \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# room 25 P(x= 1 | A) and P(x= 0|A)\n",
    "rooms_df = pd.read_csv(\"rooms_tran3.csv\")\n",
    "censor_df= pd.read_csv(\"censor_prob2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "room = 'c1'\n",
    "room_prob = rooms_df.loc[rooms_df['current_room'] == room, :]\n",
    "censor_prob = censor_df.loc[censor_df['room'] == room, :] #extract relevant probabilities \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step\n",
    "1. reset index for room_prob and censor_prob\n",
    "2. extract the probabilities from the dataset\n",
    "3. compute the P(x=1) and P(x=0) with conditions\n",
    "4. log likelihood sum \n",
    "5. return the prob of room "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2056843679880329\n",
      "0.3518344308560677\n"
     ]
    }
   ],
   "source": [
    "def prob_have_people(state,trans, room):\n",
    "    \"trans is the dictionary from rooms_tran/ censor trans; state is a dictionary with room as key and (p(0), p(1)) as value \"\n",
    "    prob_have = trans['(1, 1)']*state[room][1] +  trans[\"(1, 0)\"]*state[room][0]\n",
    "    return (prob_have)\n",
    "    \n",
    "def prob_no_people(state,trans, room):    \n",
    "    prob_no = trans[\"(0, 1)\"]*state[room][1] +  trans[\"(0, 0)\"]*state[room][0] \n",
    "    return (prob_no)\n",
    "\n",
    "room_prob_tem = room_prob.set_index('previous_room')\n",
    "state_tem = {'c2': (1.0,0)}\n",
    "trans_tem = room_prob_tem.loc['c2',:].to_dict()\n",
    "#print(trans_tem)\n",
    "\n",
    "print(prob_have_people(state_tem, trans_tem,\"c2\"))\n",
    "\n",
    "print(prob_no_people(state_tem, trans_tem,\"c2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_prob_room(curr_room, room_prob_df, state):\n",
    "    list_have_people = []\n",
    "    list_no_people = []\n",
    "    room_prob_tem =room_prob_df.set_index('previous_room')\n",
    "    for rooms in room_prob_df['previous_room']:\n",
    "        room_dict = room_prob_tem.loc[rooms,:].to_dict()\n",
    "        have_people = prob_have_people(state,room_dict, rooms)\n",
    "        no_people =  prob_no_people(state,room_dict, rooms)\n",
    "        list_have_people.append(have_people)\n",
    "        list_no_people.append(no_people)\n",
    "    \n",
    "    prob_have = np.prod(list_have_people)\n",
    "    prob_no = np.prod(list_no_people)\n",
    "    \n",
    "    prob_have = prob_have/ (prob_have+ prob_no)\n",
    "    prob_no = 1- prob_have  \n",
    "    \n",
    "    return(( prob_no,prob_have))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c4': (0.8, 0.2), 'r3': (0.8, 0.2), 'r25': (0.8, 0.2), 'r34': (0.8, 0.2), 'r26': (0.8, 0.2), 'r22': (0.8, 0.2), 'r7': (0.8, 0.2), 'c2': (0.8, 0.2), 'c1': (0.8, 0.2)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9470487486017466, 0.05295125139825336)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_tem = {room : (0.8,0.2) for room in room_prob['previous_room'] }\n",
    "print(state_tem)\n",
    "\n",
    "probability_room = joint_prob_room(room, room_prob, state_tem)\n",
    "probability_room"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. censors \n",
    "2. combine the prob\n",
    "3. iterate all rooms in one timestep \n",
    "4. all rooms all time \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def censor_cal(curr_room, censor_prob_df, state):\n",
    "    list_have_people = []\n",
    "    list_no_people = []\n",
    "    censor_prob_tem = censor_prob_df.set_index('censor')\n",
    "    for censors in censor_prob_df['censor']:\n",
    "        censor_dict = censor_prob_tem.loc[censors,:].to_dict()\n",
    "        have_people = prob_have_people(state, censor_dict, censors )\n",
    "        no_people = prob_no_people(state, censor_dict, censors )\n",
    "        list_have_people.append(have_people)\n",
    "        list_no_people.append(no_people)\n",
    "    \n",
    "    prob_have = np.prod(list_have_people)\n",
    "    prob_no = np.prod(list_no_people)\n",
    "\n",
    "    \n",
    "    prob_have = prob_have/ (prob_have+ prob_no)\n",
    "    prob_no = 1- prob_have  \n",
    "    return(( prob_no, prob_have))\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4925900982912593, 0.5074099017087407)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_temp = {'reliable_sensor3': (0.0,1.0)} \n",
    "probability_censor = censor_cal('c1',censor_prob,state_temp)\n",
    "probability_censor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def joint_prob(prob_room, prob_censor, weight):\n",
    "    no_people = prob_room[0] * weight[0] * prob_censor[0] * weight[1]\n",
    "    have_people = prob_room[1] * weight[0] * prob_censor[1] * weight[1]\n",
    "    \n",
    "    prob_have = have_people/ (have_people+ no_people)\n",
    "    prob_no = 1- prob_have \n",
    "    \n",
    "    return(( prob_no, prob_have))\n",
    "\n",
    "def make_decision(prob_room, prob_censor, weight, theta):\n",
    "    people = 0\n",
    "    no_people = prob_room[0] * weight[0] * prob_censor[0] * weight[1]\n",
    "    have_people = prob_room[1] * weight[0] * prob_censor[1] * weight[1]\n",
    "    \n",
    "    prob_have = have_people/ (have_people+ no_people)\n",
    "    if prob_have > theta: \n",
    "        people = 1\n",
    "    return(people)\n",
    "    \n",
    "make_decision(probability_room, probability_censor, [1,9], 0.5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do all rooms at one time stamp given previous time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = data.sample(1)\n",
    "censor_sample = data_sample.iloc[:,1:9]\n",
    "room_sample = data_sample.iloc[:,17:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reliable_sensor1': (1, 0),\n",
       " 'reliable_sensor2': (0, 1),\n",
       " 'reliable_sensor3': (0, 1),\n",
       " 'reliable_sensor4': (0, 1),\n",
       " 'unreliable_sensor1': (1, 0),\n",
       " 'unreliable_sensor2': (1, 0),\n",
       " 'unreliable_sensor3': (1, 0),\n",
       " 'unreliable_sensor4': (1, 0)}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "room_dict = room_sample.to_dict()\n",
    "room_state = {k: list(v.values())[0] for k, v in room_dict.items()}\n",
    "room_state2 = {k: (0,1) if v > 0 else (1,0) for k,v in room_state.items() }\n",
    "\n",
    "censor_dict = censor_sample.to_dict()\n",
    "censor_state = {k: list(v.values())[0] for k, v in censor_dict.items()}\n",
    "censor_state2 = {k: (0,1) if v == \"motion\" else (1,0) for k,v in censor_state.items() }\n",
    "censor_state2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_state(data_dict, room_info):\n",
    "    if room_info == \"room\":\n",
    "        data_state = {k: list(v.values())[0] for k, v in data_dict.items()}\n",
    "        data_state2 = {k: (0,1) if v > 0 else (1,0) for k,v in data_state.items() }\n",
    "    if room_info == \"censor\":\n",
    "        #data_state = {k: list(v.values())[0] for k, v in data_dict.items()}\n",
    "        data_state2= {k: (0,1) if v == \"motion\" else (1,0) for k,v in data_dict.items() }\n",
    "    return(data_state2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_room_predict(room_state, censors_state, room_prob_df, censor_prob_df, w, theta = 0.5):\n",
    "    room_predict_dict = {}\n",
    "    room_list = list(room_state.keys())\n",
    "    room_list = [room for room in room_list]\n",
    "    for room in room_list: \n",
    "        room_prob = room_prob_df.loc[room_prob_df['current_room'] == room, :]\n",
    "        censor_prob =  censor_prob_df.loc[censor_prob_df['room'] == room, :]\n",
    "        probability_room = joint_prob_room(room, room_prob, room_state)\n",
    "        probability_censor = censor_cal(room,censor_prob,censors_state)\n",
    "        room_predict_dict[room] = joint_prob(probability_room , probability_censor, w )\n",
    "        \n",
    "    return room_predict_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'r1': (0.9974229512106813, 0.0025770487893187243),\n",
       " 'r2': (0.723657410068943, 0.276342589931057),\n",
       " 'r3': (0.06566990405806616, 0.9343300959419338),\n",
       " 'r4': (0.9600772353397823, 0.03992276466021776),\n",
       " 'r5': (0.0011309404790580402, 0.998869059520942),\n",
       " 'r6': (0.900148428675396, 0.099851571324604),\n",
       " 'r7': (0.13037362396293917, 0.8696263760370608),\n",
       " 'r8': (0.49406553049687485, 0.5059344695031252),\n",
       " 'r9': (0.8464211309285306, 0.1535788690714695),\n",
       " 'r10': (0.5337915699721013, 0.4662084300278987),\n",
       " 'r11': (0.957012071468477, 0.04298792853152301),\n",
       " 'r12': (0.9017510875213329, 0.0982489124786671),\n",
       " 'r13': (0.9724594389292762, 0.027540561070723776),\n",
       " 'r14': (0.9708343227627803, 0.0291656772372198),\n",
       " 'r15': (0.011552728050316152, 0.9884472719496838),\n",
       " 'r16': (0.9981927826621926, 0.001807217337807407),\n",
       " 'r17': (0.9936994581104033, 0.006300541889596699),\n",
       " 'r18': (0.003973816797989138, 0.9960261832020109),\n",
       " 'r19': (0.016500236150219116, 0.9834997638497809),\n",
       " 'r20': (0.9928896191707224, 0.0071103808292776426),\n",
       " 'r21': (0.5752975909828602, 0.42470240901713985),\n",
       " 'r22': (0.9596466425149037, 0.04035335748509624),\n",
       " 'r23': (0.9758165013251542, 0.024183498674845854),\n",
       " 'r24': (0.9638919650242328, 0.036108034975767145),\n",
       " 'r25': (0.002054805120602965, 0.997945194879397),\n",
       " 'r26': (0.7120013741834934, 0.2879986258165066),\n",
       " 'r27': (0.9910621425566551, 0.008937857443344877),\n",
       " 'r28': (nan, nan),\n",
       " 'r29': (0.005280817387227743, 0.9947191826127723),\n",
       " 'r30': (0.0, 1.0),\n",
       " 'r31': (0.0002268039215549411, 0.9997731960784451),\n",
       " 'r32': (0.9602041554864224, 0.03979584451357764),\n",
       " 'r33': (0.014719647355109444, 0.9852803526448906),\n",
       " 'r34': (0.9340461931771615, 0.06595380682283847),\n",
       " 'r35': (0.3999076551811521, 0.6000923448188479),\n",
       " 'c1': (0.1366139742325082, 0.8633860257674918),\n",
       " 'c2': (0.694599164443284, 0.30540083555671604),\n",
       " 'c3': (0.7480738049298252, 0.2519261950701747),\n",
       " 'c4': (1.0, 0.0),\n",
       " 'o1': (0.9921960959373497, 0.007803904062650355),\n",
       " 'outside': (0.9919812584106082, 0.008018741589391766)}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_room_predict(room_state2,censor_state2, rooms_df,censor_df, [1,1]  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do all the timestep recursively \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_state = data.head(1)\n",
    "first_room_dict = first_state.iloc[:,17:].to_dict()\n",
    "first_room_state = dict_to_state(first_room_dict, \"room\")\n",
    "\n",
    "first_censor_dict =  data_sample.iloc[:,1:9].to_dict()\n",
    "first_censor_state = dict_to_state(first_censor_dict, \"censor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r1': (0.9986244715036079, 0.001375528496392076),\n",
       " 'r2': (0.6922010401567693, 0.30779895984323075),\n",
       " 'r3': (0.8732633933311361, 0.1267366066688639),\n",
       " 'r4': (0.9600772353397823, 0.03992276466021776),\n",
       " 'r5': (0.9886982664271079, 0.011301733572892068),\n",
       " 'r6': (0.9771555875354426, 0.022844412464557422),\n",
       " 'r7': (0.9954139822229566, 0.004586017777043351),\n",
       " 'r8': (0.6320732949188523, 0.3679267050811477),\n",
       " 'r9': (0.9153211316891529, 0.08467886831084712),\n",
       " 'r10': (0.9999992618258357, 7.381741643118151e-07),\n",
       " 'r11': (0.9988210935150521, 0.0011789064849479496),\n",
       " 'r12': (0.0030587850915568815, 0.9969412149084431),\n",
       " 'r13': (0.9678923909972318, 0.03210760900276821),\n",
       " 'r14': (0.9708343227627803, 0.0291656772372198),\n",
       " 'r15': (0.9996939216388571, 0.0003060783611429342),\n",
       " 'r16': (0.9998517166554253, 0.00014828334457477882),\n",
       " 'r17': (0.9832359406400615, 0.016764059359938556),\n",
       " 'r18': (0.9721484193778249, 0.027851580622175045),\n",
       " 'r19': (0.9984502374200425, 0.0015497625799575092),\n",
       " 'r20': (0.9457462152783527, 0.05425378472164736),\n",
       " 'r21': (0.9563587937931336, 0.043641206206866394),\n",
       " 'r22': (0.013983189746353042, 0.986016810253647),\n",
       " 'r23': (0.9758165013251542, 0.024183498674845854),\n",
       " 'r24': (0.9638919650242328, 0.036108034975767145),\n",
       " 'r25': (0.9948446085425839, 0.00515539145741603),\n",
       " 'r26': (0.8985702687731946, 0.10142973122680547),\n",
       " 'r27': (0.8596068505918449, 0.1403931494081551),\n",
       " 'r28': (0.9669937511057166, 0.03300624889428341),\n",
       " 'r29': (0.9426828733952142, 0.057317126604785794),\n",
       " 'r30': (0.9265645378599701, 0.07343546214002997),\n",
       " 'r31': (0.9993446678306473, 0.000655332169352614),\n",
       " 'r32': (0.7438238318633321, 0.2561761681366679),\n",
       " 'r33': (0.9621873496794516, 0.03781265032054839),\n",
       " 'r34': (0.9932941764451796, 0.006705823554820359),\n",
       " 'r35': (0.8712319233306709, 0.12876807666932916),\n",
       " 'c1': (0.9988710790713583, 0.0011289209286416942),\n",
       " 'c2': (0.9480192240957424, 0.05198077590425768),\n",
       " 'c3': (0.9862214654516521, 0.013778534548347876),\n",
       " 'c4': (1.0, 0.0),\n",
       " 'o1': (0.9944014229164253, 0.0055985770835747396),\n",
       " 'outside': (0.0005633036254475421, 0.9994366963745525)}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_room_predict(first_room_state,first_censor_state, rooms_df,censor_df, [1,9]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_prob =[]\n",
    "for idx, value in data.time.items():\n",
    "    curr_censor = data.iloc[idx,1:9].to_dict()\n",
    "    curr_censor_state = dict_to_state(curr_censor, \"censor\")\n",
    "    \n",
    "    if idx == 0:\n",
    "        current_room_state = first_room_state\n",
    "    else: \n",
    "        current_room_state = list_prob[idx-1]\n",
    "    \n",
    "    room_predict = all_room_predict(current_room_state,curr_censor_state, rooms_df,censor_df, [1,9]  )\n",
    "    list_prob.append(room_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_df= pd.DataFrame(list_prob)\n",
    "#pro_df.to_csv('predict2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_on(prob, theta = 0.7):\n",
    "    turn_on = 1 \n",
    "    if prob[0] > theta:\n",
    "        turn_on = 0\n",
    "    return(turn_on)\n",
    "\n",
    "def have_people(number):\n",
    "    turn_on = 1 \n",
    "    if number < 0.1:\n",
    "        turn_on = 0\n",
    "    return (turn_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_df = pro_df.applymap(turn_on)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_data = data.iloc[:,17:].applymap(have_people)\n",
    "def calculate_cost (light,people):\n",
    "    if light == 1:\n",
    "        cost = 1 \n",
    "    if light == 0:\n",
    "        cost = people*4\n",
    "    return(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05714285714285714,\n",
       " 0.11428571428571428,\n",
       " 0.2,\n",
       " 0.2571428571428571,\n",
       " 0.2571428571428571,\n",
       " 0.3142857142857143,\n",
       " 0.3142857142857143,\n",
       " 0.2857142857142857,\n",
       " 0.34285714285714286,\n",
       " 0.3142857142857143,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.4,\n",
       " 0.42857142857142855,\n",
       " 0.5142857142857142,\n",
       " 0.4857142857142857,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.4857142857142857,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.37142857142857144,\n",
       " 0.34285714285714286,\n",
       " 0.34285714285714286,\n",
       " 0.34285714285714286,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.3142857142857143,\n",
       " 0.3142857142857143,\n",
       " 0.34285714285714286,\n",
       " 0.2857142857142857,\n",
       " 0.2857142857142857,\n",
       " 0.2857142857142857,\n",
       " 0.3142857142857143,\n",
       " 0.4,\n",
       " 0.3142857142857143,\n",
       " 0.22857142857142856,\n",
       " 0.3142857142857143,\n",
       " 0.2571428571428571,\n",
       " 0.34285714285714286,\n",
       " 0.37142857142857144,\n",
       " 0.2571428571428571,\n",
       " 0.4,\n",
       " 0.34285714285714286,\n",
       " 0.37142857142857144,\n",
       " 0.34285714285714286,\n",
       " 0.34285714285714286,\n",
       " 0.37142857142857144,\n",
       " 0.4,\n",
       " 0.42857142857142855,\n",
       " 0.37142857142857144,\n",
       " 0.4,\n",
       " 0.37142857142857144,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.37142857142857144,\n",
       " 0.4,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.34285714285714286,\n",
       " 0.3142857142857143,\n",
       " 0.34285714285714286,\n",
       " 0.34285714285714286,\n",
       " 0.34285714285714286,\n",
       " 0.3142857142857143,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.34285714285714286,\n",
       " 0.2857142857142857,\n",
       " 0.2571428571428571,\n",
       " 0.2857142857142857,\n",
       " 0.2571428571428571,\n",
       " 0.2571428571428571,\n",
       " 0.22857142857142856,\n",
       " 0.2,\n",
       " 0.22857142857142856,\n",
       " 0.22857142857142856,\n",
       " 0.22857142857142856,\n",
       " 0.2571428571428571,\n",
       " 0.2857142857142857,\n",
       " 0.3142857142857143,\n",
       " 0.3142857142857143,\n",
       " 0.2857142857142857,\n",
       " 0.34285714285714286,\n",
       " 0.3142857142857143,\n",
       " 0.2857142857142857,\n",
       " 0.2857142857142857,\n",
       " 0.2857142857142857,\n",
       " 0.2571428571428571,\n",
       " 0.2857142857142857,\n",
       " 0.2571428571428571,\n",
       " 0.22857142857142856,\n",
       " 0.3142857142857143,\n",
       " 0.34285714285714286,\n",
       " 0.2571428571428571,\n",
       " 0.2857142857142857,\n",
       " 0.2857142857142857,\n",
       " 0.3142857142857143,\n",
       " 0.2571428571428571,\n",
       " 0.2857142857142857,\n",
       " 0.2857142857142857,\n",
       " 0.3142857142857143,\n",
       " 0.2857142857142857,\n",
       " 0.2857142857142857,\n",
       " 0.2857142857142857,\n",
       " 0.2857142857142857,\n",
       " 0.2857142857142857,\n",
       " 0.2571428571428571,\n",
       " 0.2857142857142857,\n",
       " 0.3142857142857143,\n",
       " 0.34285714285714286,\n",
       " 0.2571428571428571,\n",
       " 0.34285714285714286,\n",
       " 0.34285714285714286,\n",
       " 0.2571428571428571,\n",
       " 0.3142857142857143,\n",
       " 0.2571428571428571,\n",
       " 0.2857142857142857,\n",
       " 0.3142857142857143,\n",
       " 0.2857142857142857,\n",
       " 0.2857142857142857,\n",
       " 0.34285714285714286,\n",
       " 0.34285714285714286,\n",
       " 0.34285714285714286,\n",
       " 0.37142857142857144,\n",
       " 0.34285714285714286,\n",
       " 0.34285714285714286,\n",
       " 0.34285714285714286,\n",
       " 0.34285714285714286,\n",
       " 0.3142857142857143,\n",
       " 0.3142857142857143,\n",
       " 0.3142857142857143,\n",
       " 0.37142857142857144,\n",
       " 0.34285714285714286,\n",
       " 0.34285714285714286,\n",
       " 0.37142857142857144,\n",
       " 0.2857142857142857,\n",
       " 0.3142857142857143,\n",
       " 0.3142857142857143,\n",
       " 0.2857142857142857,\n",
       " 0.3142857142857143,\n",
       " 0.2857142857142857,\n",
       " 0.3142857142857143,\n",
       " 0.3142857142857143,\n",
       " 0.3142857142857143,\n",
       " 0.2857142857142857,\n",
       " 0.2571428571428571,\n",
       " 0.2571428571428571,\n",
       " 0.2571428571428571,\n",
       " 0.2857142857142857,\n",
       " 0.2857142857142857,\n",
       " 0.2,\n",
       " 0.22857142857142856,\n",
       " 0.3142857142857143,\n",
       " 0.2857142857142857,\n",
       " 0.2857142857142857,\n",
       " 0.3142857142857143,\n",
       " 0.2571428571428571,\n",
       " 0.2571428571428571,\n",
       " 0.2571428571428571,\n",
       " 0.2571428571428571,\n",
       " 0.2571428571428571,\n",
       " 0.2,\n",
       " 0.2571428571428571,\n",
       " 0.2857142857142857,\n",
       " 0.2571428571428571,\n",
       " 0.34285714285714286,\n",
       " 0.3142857142857143,\n",
       " 0.34285714285714286,\n",
       " 0.34285714285714286,\n",
       " 0.3142857142857143,\n",
       " 0.2571428571428571,\n",
       " 0.2857142857142857,\n",
       " 0.2857142857142857,\n",
       " 0.2857142857142857,\n",
       " 0.34285714285714286,\n",
       " 0.2857142857142857,\n",
       " 0.3142857142857143,\n",
       " 0.34285714285714286,\n",
       " 0.3142857142857143,\n",
       " 0.3142857142857143,\n",
       " 0.34285714285714286,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.37142857142857144,\n",
       " 0.42857142857142855,\n",
       " 0.37142857142857144,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.37142857142857144,\n",
       " 0.34285714285714286,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.34285714285714286,\n",
       " 0.37142857142857144,\n",
       " 0.34285714285714286,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.37142857142857144,\n",
       " 0.42857142857142855,\n",
       " 0.5428571428571428,\n",
       " 0.4857142857142857,\n",
       " 0.4,\n",
       " 0.5142857142857142,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.4857142857142857,\n",
       " 0.4,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.42857142857142855,\n",
       " 0.37142857142857144,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.37142857142857144,\n",
       " 0.34285714285714286,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.42857142857142855,\n",
       " 0.4857142857142857,\n",
       " 0.5142857142857142,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.5142857142857142,\n",
       " 0.5428571428571428,\n",
       " 0.5428571428571428,\n",
       " 0.5714285714285714,\n",
       " 0.5428571428571428,\n",
       " 0.45714285714285713,\n",
       " 0.5428571428571428,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.5714285714285714,\n",
       " 0.5142857142857142,\n",
       " 0.4857142857142857,\n",
       " 0.45714285714285713,\n",
       " 0.4857142857142857,\n",
       " 0.42857142857142855,\n",
       " 0.4857142857142857,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.5142857142857142,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.34285714285714286,\n",
       " 0.34285714285714286,\n",
       " 0.34285714285714286,\n",
       " 0.4,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.4,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.45714285714285713,\n",
       " 0.4857142857142857,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.4857142857142857,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.5428571428571428,\n",
       " 0.5714285714285714,\n",
       " 0.5428571428571428,\n",
       " 0.5142857142857142,\n",
       " 0.5714285714285714,\n",
       " 0.5714285714285714,\n",
       " 0.5142857142857142,\n",
       " 0.5428571428571428,\n",
       " 0.5142857142857142,\n",
       " 0.4857142857142857,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.45714285714285713,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.45714285714285713,\n",
       " 0.5142857142857142,\n",
       " 0.5428571428571428,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.5714285714285714,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.5428571428571428,\n",
       " 0.5428571428571428,\n",
       " 0.5428571428571428,\n",
       " 0.5428571428571428,\n",
       " 0.5428571428571428,\n",
       " 0.5428571428571428,\n",
       " 0.5428571428571428,\n",
       " 0.5428571428571428,\n",
       " 0.5428571428571428,\n",
       " 0.5428571428571428,\n",
       " 0.5714285714285714,\n",
       " 0.5428571428571428,\n",
       " 0.5428571428571428,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.5428571428571428,\n",
       " 0.5142857142857142,\n",
       " 0.5428571428571428,\n",
       " 0.5428571428571428,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.6285714285714286,\n",
       " 0.6285714285714286,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.5428571428571428,\n",
       " 0.5714285714285714,\n",
       " 0.6,\n",
       " 0.5714285714285714,\n",
       " 0.5142857142857142,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.45714285714285713,\n",
       " 0.4,\n",
       " 0.4857142857142857,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.45714285714285713,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.5428571428571428,\n",
       " 0.4857142857142857,\n",
       " 0.5428571428571428,\n",
       " 0.5142857142857142,\n",
       " 0.4857142857142857,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.37142857142857144,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.42857142857142855,\n",
       " 0.37142857142857144,\n",
       " 0.34285714285714286,\n",
       " 0.37142857142857144,\n",
       " 0.34285714285714286,\n",
       " 0.34285714285714286,\n",
       " 0.42857142857142855,\n",
       " 0.4857142857142857,\n",
       " 0.37142857142857144,\n",
       " 0.3142857142857143,\n",
       " 0.3142857142857143,\n",
       " 0.3142857142857143,\n",
       " 0.34285714285714286,\n",
       " 0.3142857142857143,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.5142857142857142,\n",
       " 0.5428571428571428,\n",
       " 0.5428571428571428,\n",
       " 0.5714285714285714,\n",
       " 0.5714285714285714,\n",
       " 0.5428571428571428,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.45714285714285713,\n",
       " 0.4857142857142857,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.5428571428571428,\n",
       " 0.5428571428571428,\n",
       " 0.5428571428571428,\n",
       " 0.5428571428571428,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.5142857142857142,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.5142857142857142,\n",
       " 0.4857142857142857,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.45714285714285713,\n",
       " 0.4857142857142857,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.4857142857142857,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.4857142857142857,\n",
       " 0.45714285714285713,\n",
       " 0.4857142857142857,\n",
       " 0.4,\n",
       " 0.4857142857142857,\n",
       " 0.45714285714285713,\n",
       " 0.5142857142857142,\n",
       " 0.4857142857142857,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.4,\n",
       " 0.4857142857142857,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.37142857142857144,\n",
       " 0.4,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4857142857142857,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.5142857142857142,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.4857142857142857,\n",
       " 0.5428571428571428,\n",
       " 0.37142857142857144,\n",
       " 0.45714285714285713,\n",
       " 0.4,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.4857142857142857,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.5142857142857142,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.37142857142857144,\n",
       " 0.4857142857142857,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.37142857142857144,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.4857142857142857,\n",
       " 0.5142857142857142,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.45714285714285713,\n",
       " 0.6,\n",
       " 0.5428571428571428,\n",
       " 0.4857142857142857,\n",
       " 0.5142857142857142,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.45714285714285713,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.5428571428571428,\n",
       " 0.5142857142857142,\n",
       " 0.5714285714285714,\n",
       " 0.5428571428571428,\n",
       " 0.5714285714285714,\n",
       " 0.5142857142857142,\n",
       " 0.4857142857142857,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.5428571428571428,\n",
       " 0.5714285714285714,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.5714285714285714,\n",
       " 0.5714285714285714,\n",
       " 0.6,\n",
       " 0.4857142857142857,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.37142857142857144,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.34285714285714286,\n",
       " 0.4,\n",
       " 0.37142857142857144,\n",
       " 0.34285714285714286,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.34285714285714286,\n",
       " 0.34285714285714286,\n",
       " 0.37142857142857144,\n",
       " 0.34285714285714286,\n",
       " 0.37142857142857144,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.4,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.37142857142857144,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.4857142857142857,\n",
       " 0.45714285714285713,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.4857142857142857,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.45714285714285713,\n",
       " 0.4,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.34285714285714286,\n",
       " 0.34285714285714286,\n",
       " 0.34285714285714286,\n",
       " 0.3142857142857143,\n",
       " 0.3142857142857143,\n",
       " 0.3142857142857143,\n",
       " 0.3142857142857143,\n",
       " 0.34285714285714286,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.4,\n",
       " 0.34285714285714286,\n",
       " 0.3142857142857143,\n",
       " 0.3142857142857143,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.34285714285714286,\n",
       " 0.37142857142857144,\n",
       " 0.3142857142857143,\n",
       " 0.34285714285714286,\n",
       " 0.34285714285714286,\n",
       " 0.3142857142857143,\n",
       " 0.34285714285714286,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.37142857142857144,\n",
       " 0.4,\n",
       " 0.37142857142857144,\n",
       " 0.4857142857142857,\n",
       " 0.5142857142857142,\n",
       " 0.4857142857142857,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.4857142857142857,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.45714285714285713,\n",
       " 0.4857142857142857,\n",
       " 0.45714285714285713,\n",
       " 0.5142857142857142,\n",
       " 0.4857142857142857,\n",
       " 0.5714285714285714,\n",
       " 0.5142857142857142,\n",
       " 0.4857142857142857,\n",
       " 0.5428571428571428,\n",
       " 0.5428571428571428,\n",
       " 0.5714285714285714,\n",
       " 0.5428571428571428,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.4857142857142857,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.5714285714285714,\n",
       " 0.5714285714285714,\n",
       " 0.5714285714285714,\n",
       " 0.5428571428571428,\n",
       " 0.5428571428571428,\n",
       " 0.5428571428571428,\n",
       " 0.6,\n",
       " 0.6285714285714286,\n",
       " 0.5714285714285714,\n",
       " 0.5428571428571428,\n",
       " 0.5714285714285714,\n",
       " 0.5714285714285714,\n",
       " 0.5714285714285714,\n",
       " 0.5714285714285714,\n",
       " 0.5714285714285714,\n",
       " 0.5142857142857142,\n",
       " 0.5142857142857142,\n",
       " 0.4857142857142857,\n",
       " 0.4,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.4857142857142857,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.34285714285714286,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.5142857142857142,\n",
       " 0.5428571428571428,\n",
       " 0.5142857142857142,\n",
       " 0.4857142857142857,\n",
       " 0.5428571428571428,\n",
       " 0.6,\n",
       " 0.5714285714285714,\n",
       " 0.5714285714285714,\n",
       " 0.5428571428571428,\n",
       " 0.4857142857142857,\n",
       " 0.5142857142857142,\n",
       " 0.4857142857142857,\n",
       " 0.5428571428571428,\n",
       " 0.5428571428571428,\n",
       " 0.5714285714285714,\n",
       " 0.5428571428571428,\n",
       " 0.5428571428571428,\n",
       " 0.5142857142857142,\n",
       " 0.42857142857142855,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.5142857142857142,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.5142857142857142,\n",
       " 0.45714285714285713,\n",
       " 0.5142857142857142,\n",
       " 0.5428571428571428,\n",
       " 0.4857142857142857,\n",
       " 0.45714285714285713,\n",
       " 0.4857142857142857,\n",
       " 0.45714285714285713,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.5142857142857142,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.4857142857142857,\n",
       " 0.42857142857142855,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.37142857142857144,\n",
       " 0.4,\n",
       " 0.34285714285714286,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.42857142857142855,\n",
       " 0.3142857142857143,\n",
       " 0.34285714285714286,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.37142857142857144,\n",
       " 0.34285714285714286,\n",
       " 0.37142857142857144,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.37142857142857144,\n",
       " 0.34285714285714286,\n",
       " 0.4,\n",
       " 0.3142857142857143,\n",
       " 0.3142857142857143,\n",
       " 0.3142857142857143,\n",
       " 0.34285714285714286,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4857142857142857,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.37142857142857144,\n",
       " 0.34285714285714286,\n",
       " 0.34285714285714286,\n",
       " 0.4,\n",
       " 0.37142857142857144,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.42857142857142855,\n",
       " 0.34285714285714286,\n",
       " 0.3142857142857143,\n",
       " 0.3142857142857143,\n",
       " 0.34285714285714286,\n",
       " 0.37142857142857144,\n",
       " 0.3142857142857143,\n",
       " 0.34285714285714286,\n",
       " 0.2857142857142857,\n",
       " 0.2857142857142857,\n",
       " 0.2571428571428571,\n",
       " 0.2571428571428571,\n",
       " 0.2857142857142857,\n",
       " 0.34285714285714286,\n",
       " 0.3142857142857143,\n",
       " 0.2857142857142857,\n",
       " 0.3142857142857143,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.34285714285714286,\n",
       " 0.4,\n",
       " 0.37142857142857144,\n",
       " 0.37142857142857144,\n",
       " 0.45714285714285713,\n",
       " 0.42857142857142855,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.45714285714285713,\n",
       " 0.4857142857142857,\n",
       " 0.4857142857142857,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.42857142857142855,\n",
       " 0.4,\n",
       " 0.3142857142857143,\n",
       " 0.34285714285714286,\n",
       " 0.4,\n",
       " 0.4,\n",
       " ...]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_error = []\n",
    "for idx, value in data.time.items():\n",
    "    error_list = true_data.iloc[idx,:] - decision_df.iloc[idx,:]\n",
    "    errors = sum(x != 0 for x in error_list[:35])\n",
    "    total_error.append(errors)\n",
    "\n",
    "total_error\n",
    "error_rate = [i/35 for i in total_error]\n",
    "error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cost = []\n",
    "for idx, value in data.time.items():\n",
    "    cost_list = [calculate_cost(i,j) for i,j in zip(decision_df.iloc[idx,:35],data.iloc[idx,17:])]\n",
    "    cost = sum(cost_list)\n",
    "    total_cost.append(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114531"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(total_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 6,\n",
       " 10,\n",
       " 11,\n",
       " 11,\n",
       " 19,\n",
       " 12,\n",
       " 11,\n",
       " 17,\n",
       " 13,\n",
       " 33,\n",
       " 46,\n",
       " 46,\n",
       " 35,\n",
       " 45,\n",
       " 55,\n",
       " 62,\n",
       " 71,\n",
       " 70,\n",
       " 70,\n",
       " 70,\n",
       " 70,\n",
       " 70,\n",
       " 63,\n",
       " 65,\n",
       " 63,\n",
       " 62,\n",
       " 61,\n",
       " 61,\n",
       " 61,\n",
       " 65,\n",
       " 61,\n",
       " 65,\n",
       " 57,\n",
       " 57,\n",
       " 61,\n",
       " 65,\n",
       " 65,\n",
       " 65,\n",
       " 56,\n",
       " 56,\n",
       " 51,\n",
       " 49,\n",
       " 50,\n",
       " 50,\n",
       " 48,\n",
       " 51,\n",
       " 50,\n",
       " 45,\n",
       " 50,\n",
       " 46,\n",
       " 48,\n",
       " 53,\n",
       " 44,\n",
       " 47,\n",
       " 46,\n",
       " 51,\n",
       " 46,\n",
       " 46,\n",
       " 47,\n",
       " 50,\n",
       " 51,\n",
       " 50,\n",
       " 51,\n",
       " 47,\n",
       " 51,\n",
       " 48,\n",
       " 51,\n",
       " 62,\n",
       " 60,\n",
       " 60,\n",
       " 59,\n",
       " 56,\n",
       " 56,\n",
       " 55,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 53,\n",
       " 51,\n",
       " 52,\n",
       " 55,\n",
       " 48,\n",
       " 47,\n",
       " 47,\n",
       " 49,\n",
       " 47,\n",
       " 48,\n",
       " 47,\n",
       " 46,\n",
       " 47,\n",
       " 47,\n",
       " 42,\n",
       " 43,\n",
       " 43,\n",
       " 41,\n",
       " 41,\n",
       " 46,\n",
       " 48,\n",
       " 44,\n",
       " 42,\n",
       " 38,\n",
       " 46,\n",
       " 43,\n",
       " 41,\n",
       " 40,\n",
       " 29,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 31,\n",
       " 37,\n",
       " 38,\n",
       " 38,\n",
       " 35,\n",
       " 36,\n",
       " 35,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 30,\n",
       " 33,\n",
       " 30,\n",
       " 29,\n",
       " 34,\n",
       " 35,\n",
       " 30,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 33,\n",
       " 34,\n",
       " 33,\n",
       " 34,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 35,\n",
       " 35,\n",
       " 40,\n",
       " 36,\n",
       " 43,\n",
       " 40,\n",
       " 34,\n",
       " 38,\n",
       " 34,\n",
       " 35,\n",
       " 38,\n",
       " 35,\n",
       " 35,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 41,\n",
       " 40,\n",
       " 40,\n",
       " 36,\n",
       " 36,\n",
       " 32,\n",
       " 36,\n",
       " 36,\n",
       " 41,\n",
       " 40,\n",
       " 40,\n",
       " 41,\n",
       " 36,\n",
       " 37,\n",
       " 37,\n",
       " 36,\n",
       " 40,\n",
       " 39,\n",
       " 40,\n",
       " 36,\n",
       " 35,\n",
       " 31,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 29,\n",
       " 29,\n",
       " 23,\n",
       " 30,\n",
       " 35,\n",
       " 32,\n",
       " 32,\n",
       " 29,\n",
       " 31,\n",
       " 32,\n",
       " 31,\n",
       " 33,\n",
       " 34,\n",
       " 26,\n",
       " 31,\n",
       " 35,\n",
       " 34,\n",
       " 42,\n",
       " 42,\n",
       " 43,\n",
       " 47,\n",
       " 43,\n",
       " 40,\n",
       " 43,\n",
       " 41,\n",
       " 40,\n",
       " 42,\n",
       " 40,\n",
       " 41,\n",
       " 41,\n",
       " 40,\n",
       " 41,\n",
       " 44,\n",
       " 48,\n",
       " 48,\n",
       " 45,\n",
       " 49,\n",
       " 48,\n",
       " 51,\n",
       " 52,\n",
       " 50,\n",
       " 51,\n",
       " 53,\n",
       " 52,\n",
       " 53,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 46,\n",
       " 45,\n",
       " 45,\n",
       " 49,\n",
       " 49,\n",
       " 50,\n",
       " 50,\n",
       " 50,\n",
       " 42,\n",
       " 41,\n",
       " 38,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 48,\n",
       " 49,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 46,\n",
       " 51,\n",
       " 55,\n",
       " 50,\n",
       " 43,\n",
       " 51,\n",
       " 40,\n",
       " 39,\n",
       " 43,\n",
       " 44,\n",
       " 49,\n",
       " 49,\n",
       " 48,\n",
       " 48,\n",
       " 45,\n",
       " 48,\n",
       " 36,\n",
       " 32,\n",
       " 37,\n",
       " 33,\n",
       " 37,\n",
       " 36,\n",
       " 33,\n",
       " 28,\n",
       " 32,\n",
       " 36,\n",
       " 36,\n",
       " 32,\n",
       " 32,\n",
       " 36,\n",
       " 36,\n",
       " 48,\n",
       " 48,\n",
       " 47,\n",
       " 51,\n",
       " 51,\n",
       " 51,\n",
       " 52,\n",
       " 56,\n",
       " 59,\n",
       " 60,\n",
       " 63,\n",
       " 59,\n",
       " 60,\n",
       " 59,\n",
       " 59,\n",
       " 68,\n",
       " 60,\n",
       " 60,\n",
       " 56,\n",
       " 56,\n",
       " 54,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 59,\n",
       " 57,\n",
       " 56,\n",
       " 55,\n",
       " 61,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 59,\n",
       " 44,\n",
       " 44,\n",
       " 44,\n",
       " 48,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 47,\n",
       " 47,\n",
       " 51,\n",
       " 55,\n",
       " 51,\n",
       " 48,\n",
       " 51,\n",
       " 47,\n",
       " 48,\n",
       " 44,\n",
       " 43,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 41,\n",
       " 40,\n",
       " 40,\n",
       " 43,\n",
       " 44,\n",
       " 51,\n",
       " 58,\n",
       " 46,\n",
       " 50,\n",
       " 45,\n",
       " 47,\n",
       " 51,\n",
       " 52,\n",
       " 54,\n",
       " 51,\n",
       " 51,\n",
       " 51,\n",
       " 52,\n",
       " 48,\n",
       " 47,\n",
       " 47,\n",
       " 51,\n",
       " 56,\n",
       " 55,\n",
       " 51,\n",
       " 56,\n",
       " 63,\n",
       " 59,\n",
       " 64,\n",
       " 60,\n",
       " 60,\n",
       " 64,\n",
       " 64,\n",
       " 64,\n",
       " 61,\n",
       " 64,\n",
       " 64,\n",
       " 60,\n",
       " 60,\n",
       " 52,\n",
       " 55,\n",
       " 56,\n",
       " 59,\n",
       " 59,\n",
       " 59,\n",
       " 61,\n",
       " 59,\n",
       " 59,\n",
       " 55,\n",
       " 59,\n",
       " 63,\n",
       " 63,\n",
       " 63,\n",
       " 63,\n",
       " 63,\n",
       " 63,\n",
       " 63,\n",
       " 63,\n",
       " 63,\n",
       " 64,\n",
       " 63,\n",
       " 60,\n",
       " 63,\n",
       " 63,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 71,\n",
       " 67,\n",
       " 70,\n",
       " 76,\n",
       " 73,\n",
       " 74,\n",
       " 73,\n",
       " 69,\n",
       " 73,\n",
       " 69,\n",
       " 65,\n",
       " 63,\n",
       " 70,\n",
       " 74,\n",
       " 67,\n",
       " 58,\n",
       " 50,\n",
       " 52,\n",
       " 50,\n",
       " 44,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 44,\n",
       " 44,\n",
       " 49,\n",
       " 48,\n",
       " 44,\n",
       " 48,\n",
       " 51,\n",
       " 47,\n",
       " 52,\n",
       " 51,\n",
       " 52,\n",
       " 48,\n",
       " 48,\n",
       " 47,\n",
       " 43,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 48,\n",
       " 51,\n",
       " 51,\n",
       " 48,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 42,\n",
       " 44,\n",
       " 44,\n",
       " 48,\n",
       " 44,\n",
       " 45,\n",
       " 44,\n",
       " 44,\n",
       " 45,\n",
       " 45,\n",
       " 44,\n",
       " 48,\n",
       " 44,\n",
       " 41,\n",
       " 45,\n",
       " 42,\n",
       " 41,\n",
       " 43,\n",
       " 42,\n",
       " 42,\n",
       " 46,\n",
       " 50,\n",
       " 38,\n",
       " 37,\n",
       " 41,\n",
       " 41,\n",
       " 40,\n",
       " 41,\n",
       " 49,\n",
       " 53,\n",
       " 49,\n",
       " 45,\n",
       " 42,\n",
       " 45,\n",
       " 46,\n",
       " 45,\n",
       " 43,\n",
       " 49,\n",
       " 51,\n",
       " 53,\n",
       " 56,\n",
       " 56,\n",
       " 58,\n",
       " 61,\n",
       " 64,\n",
       " 60,\n",
       " 57,\n",
       " 52,\n",
       " 52,\n",
       " 51,\n",
       " 55,\n",
       " 51,\n",
       " 51,\n",
       " 52,\n",
       " 51,\n",
       " 51,\n",
       " 55,\n",
       " 59,\n",
       " 59,\n",
       " 59,\n",
       " 59,\n",
       " 59,\n",
       " 59,\n",
       " 59,\n",
       " 59,\n",
       " 59,\n",
       " 60,\n",
       " 55,\n",
       " 59,\n",
       " 54,\n",
       " 56,\n",
       " 59,\n",
       " 59,\n",
       " 59,\n",
       " 59,\n",
       " 63,\n",
       " 65,\n",
       " 65,\n",
       " 70,\n",
       " 77,\n",
       " 69,\n",
       " 69,\n",
       " 69,\n",
       " 74,\n",
       " 74,\n",
       " 73,\n",
       " 70,\n",
       " 61,\n",
       " 65,\n",
       " 62,\n",
       " 65,\n",
       " 66,\n",
       " 59,\n",
       " 63,\n",
       " 58,\n",
       " 59,\n",
       " 56,\n",
       " 61,\n",
       " 63,\n",
       " 68,\n",
       " 64,\n",
       " 59,\n",
       " 56,\n",
       " 59,\n",
       " 58,\n",
       " 58,\n",
       " 58,\n",
       " 58,\n",
       " 54,\n",
       " 54,\n",
       " 59,\n",
       " 55,\n",
       " 60,\n",
       " 49,\n",
       " 53,\n",
       " 56,\n",
       " 48,\n",
       " 51,\n",
       " 51,\n",
       " 54,\n",
       " 59,\n",
       " 55,\n",
       " 55,\n",
       " 60,\n",
       " 54,\n",
       " 51,\n",
       " 56,\n",
       " 51,\n",
       " 51,\n",
       " 58,\n",
       " 63,\n",
       " 46,\n",
       " 54,\n",
       " 51,\n",
       " 55,\n",
       " 53,\n",
       " 55,\n",
       " 60,\n",
       " 59,\n",
       " 63,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 60,\n",
       " 61,\n",
       " 58,\n",
       " 58,\n",
       " 53,\n",
       " 62,\n",
       " 59,\n",
       " 59,\n",
       " 54,\n",
       " 56,\n",
       " 58,\n",
       " 58,\n",
       " 59,\n",
       " 66,\n",
       " 73,\n",
       " 62,\n",
       " 63,\n",
       " 66,\n",
       " 65,\n",
       " 68,\n",
       " 68,\n",
       " 64,\n",
       " 65,\n",
       " 59,\n",
       " 63,\n",
       " 63,\n",
       " 63,\n",
       " 64,\n",
       " 66,\n",
       " 64,\n",
       " 59,\n",
       " 59,\n",
       " 57,\n",
       " 63,\n",
       " 62,\n",
       " 66,\n",
       " 67,\n",
       " 71,\n",
       " 68,\n",
       " 72,\n",
       " 68,\n",
       " 69,\n",
       " 65,\n",
       " 64,\n",
       " 65,\n",
       " 72,\n",
       " 68,\n",
       " 69,\n",
       " 64,\n",
       " 65,\n",
       " 70,\n",
       " 69,\n",
       " 66,\n",
       " 67,\n",
       " 63,\n",
       " 56,\n",
       " 55,\n",
       " 56,\n",
       " 55,\n",
       " 55,\n",
       " 55,\n",
       " 60,\n",
       " 48,\n",
       " 54,\n",
       " 55,\n",
       " 52,\n",
       " 55,\n",
       " 55,\n",
       " 52,\n",
       " 60,\n",
       " 60,\n",
       " 56,\n",
       " 56,\n",
       " 51,\n",
       " 59,\n",
       " 55,\n",
       " 51,\n",
       " 51,\n",
       " 51,\n",
       " 55,\n",
       " 47,\n",
       " 44,\n",
       " 46,\n",
       " 48,\n",
       " 46,\n",
       " 54,\n",
       " 64,\n",
       " 63,\n",
       " 55,\n",
       " 68,\n",
       " 65,\n",
       " 58,\n",
       " 58,\n",
       " 63,\n",
       " 66,\n",
       " 58,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 58,\n",
       " 58,\n",
       " 55,\n",
       " 55,\n",
       " 55,\n",
       " 59,\n",
       " 55,\n",
       " 59,\n",
       " 54,\n",
       " 51,\n",
       " 52,\n",
       " 52,\n",
       " 57,\n",
       " 59,\n",
       " 52,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 44,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 51,\n",
       " 51,\n",
       " 51,\n",
       " 47,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 56,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 53,\n",
       " 52,\n",
       " 52,\n",
       " 52,\n",
       " 53,\n",
       " 52,\n",
       " 48,\n",
       " 48,\n",
       " 45,\n",
       " 45,\n",
       " 49,\n",
       " 50,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 51,\n",
       " 55,\n",
       " 55,\n",
       " 55,\n",
       " 54,\n",
       " 58,\n",
       " 58,\n",
       " 52,\n",
       " 51,\n",
       " 51,\n",
       " 47,\n",
       " 48,\n",
       " 47,\n",
       " 53,\n",
       " 61,\n",
       " 52,\n",
       " 53,\n",
       " 57,\n",
       " 54,\n",
       " 54,\n",
       " 54,\n",
       " 54,\n",
       " 53,\n",
       " 53,\n",
       " 54,\n",
       " 53,\n",
       " 56,\n",
       " 48,\n",
       " 62,\n",
       " 59,\n",
       " 55,\n",
       " 62,\n",
       " 59,\n",
       " 67,\n",
       " 63,\n",
       " 59,\n",
       " 62,\n",
       " 58,\n",
       " 59,\n",
       " 55,\n",
       " 54,\n",
       " 55,\n",
       " 52,\n",
       " 55,\n",
       " 52,\n",
       " 52,\n",
       " 55,\n",
       " 58,\n",
       " 58,\n",
       " 62,\n",
       " 54,\n",
       " 57,\n",
       " 54,\n",
       " 61,\n",
       " 62,\n",
       " 57,\n",
       " 54,\n",
       " 55,\n",
       " 54,\n",
       " 54,\n",
       " 51,\n",
       " 51,\n",
       " 47,\n",
       " 46,\n",
       " 42,\n",
       " 45,\n",
       " 50,\n",
       " 50,\n",
       " 46,\n",
       " 46,\n",
       " 46,\n",
       " 46,\n",
       " 47,\n",
       " 52,\n",
       " 51,\n",
       " 47,\n",
       " 47,\n",
       " 40,\n",
       " 40,\n",
       " 41,\n",
       " 40,\n",
       " 46,\n",
       " 51,\n",
       " 53,\n",
       " 54,\n",
       " 54,\n",
       " 53,\n",
       " 53,\n",
       " 58,\n",
       " 55,\n",
       " 55,\n",
       " 55,\n",
       " 55,\n",
       " 55,\n",
       " 55,\n",
       " 58,\n",
       " 55,\n",
       " 59,\n",
       " 58,\n",
       " 58,\n",
       " 58,\n",
       " 58,\n",
       " 58,\n",
       " 52,\n",
       " 59,\n",
       " 59,\n",
       " 58,\n",
       " 51,\n",
       " 51,\n",
       " 52,\n",
       " 54,\n",
       " 58,\n",
       " 60,\n",
       " 64,\n",
       " 60,\n",
       " 60,\n",
       " 61,\n",
       " 56,\n",
       " 59,\n",
       " 56,\n",
       " 64,\n",
       " 64,\n",
       " 68,\n",
       " 67,\n",
       " 66,\n",
       " 67,\n",
       " 66,\n",
       " 70,\n",
       " 66,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 69,\n",
       " 61,\n",
       " 63,\n",
       " 60,\n",
       " 60,\n",
       " 61,\n",
       " 60,\n",
       " 56,\n",
       " 56,\n",
       " 61,\n",
       " 57,\n",
       " 61,\n",
       " 65,\n",
       " 64,\n",
       " 61,\n",
       " 62,\n",
       " 55,\n",
       " 63,\n",
       " 63,\n",
       " 66,\n",
       " 59,\n",
       " 59,\n",
       " 58,\n",
       " 61,\n",
       " 62,\n",
       " 58,\n",
       " 58,\n",
       " 58,\n",
       " 55,\n",
       " 59,\n",
       " 56,\n",
       " 58,\n",
       " 56,\n",
       " 56,\n",
       " 57,\n",
       " 55,\n",
       " 59,\n",
       " 62,\n",
       " 58,\n",
       " 51,\n",
       " 52,\n",
       " 43,\n",
       " 48,\n",
       " 49,\n",
       " 55,\n",
       " 51,\n",
       " 40,\n",
       " 47,\n",
       " 37,\n",
       " 40,\n",
       " 49,\n",
       " 44,\n",
       " 44,\n",
       " 41,\n",
       " 44,\n",
       " 44,\n",
       " 43,\n",
       " 43,\n",
       " 40,\n",
       " 44,\n",
       " 43,\n",
       " 40,\n",
       " 39,\n",
       " 48,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 44,\n",
       " 49,\n",
       " 48,\n",
       " 51,\n",
       " 53,\n",
       " 50,\n",
       " 54,\n",
       " 52,\n",
       " 49,\n",
       " 48,\n",
       " 48,\n",
       " 50,\n",
       " 48,\n",
       " 51,\n",
       " 50,\n",
       " 54,\n",
       " 47,\n",
       " 51,\n",
       " 51,\n",
       " 55,\n",
       " 56,\n",
       " 47,\n",
       " 48,\n",
       " 42,\n",
       " 41,\n",
       " 41,\n",
       " 42,\n",
       " 42,\n",
       " 45,\n",
       " 48,\n",
       " 44,\n",
       " 48,\n",
       " 53,\n",
       " 57,\n",
       " 55,\n",
       " 60,\n",
       " 58,\n",
       " 58,\n",
       " 69,\n",
       " 66,\n",
       " 69,\n",
       " 69,\n",
       " 65,\n",
       " 65,\n",
       " 63,\n",
       " 61,\n",
       " 61,\n",
       " 57,\n",
       " 61,\n",
       " 58,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 55,\n",
       " ...]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Unnamed: 0': {193: 193}, 'previous_room': {193: 'c1'}, 'current_room': {193: 'r25'}, '(1, 1)': {193: 0.365505425}, '(1, 0)': {193: 0.634494575}, '(0, 1)': {193: 0.334360555}, '(0, 0)': {193: 0.665639445}}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'(1,1)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-0acc8eee3e04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrans_tem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob_have_people\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_tem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrans_tem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-79-0acc8eee3e04>\u001b[0m in \u001b[0;36mprob_have_people\u001b[1;34m(state, trans)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprob_have_people\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"trans is the dictionary from rooms_tran; state is a dictionary with room as key and (p(0), p(1)) as value \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprob_have\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'(1,1)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m  \u001b[0mtrans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"(1,0)\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprob_have\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '(1,1)'"
     ]
    }
   ],
   "source": [
    "def prob_have_people(state,trans):\n",
    "    \"trans is the dictionary from rooms_tran; state is a dictionary with room as key and (p(0), p(1)) as value \"\n",
    "    prob_have = trans['(1,1)']*state[1] +  trans[\"(1,0)\"]*state[0] \n",
    "    return (prob_have)\n",
    "    \n",
    "def prob_no_people(state,trans):    \n",
    "    prob_no = trans[\"(0,1)\"]*state[1] +  trans[\"(0,0)\"]*state[0] \n",
    "    return (prob_no)\n",
    "\n",
    "\n",
    "state_tem = {'c1': (1.0,0)}\n",
    "trans_tem = room_prob.loc[ room_prob['previous_room'] == 'c1',:].to_dict()\n",
    "print(trans_tem)\n",
    "\n",
    "print(prob_have_people(state_tem, trans_tem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3655"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for rooms in room_prob['previous_room']:\n",
    "    room_tran = room_prob.loc[ room_prob['previous_room'] == rooms,:].to_dict\n",
    "    room_state = current_state['rooms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_generator(room):\n",
    "    state_dict = {'dom': (room,),    \n",
    "                  'table': odict([\n",
    "        ((1,), 0.0),\n",
    "        ((0,), 1.0),\n",
    "    ])}\n",
    "    return (state_dict)\n",
    "state_info = []\n",
    "for rooms in room_prob['previous_room']:\n",
    "    state_info.append(state_generator(rooms))\n",
    "    \n",
    "state_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printFactor(f):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, a factor to print on screen\n",
    "    \"\"\"\n",
    "    # Create a empty list that we will fill in with the probability table entries\n",
    "    table = list()\n",
    "    \n",
    "    # Iterate over all keys and probability values in the table\n",
    "    for key, item in f['table'].items():\n",
    "        # Convert the tuple to a list to be able to manipulate it\n",
    "        k = list(key)\n",
    "        # Append the probability value to the list with key values\n",
    "        k.append(item)\n",
    "        # Append an entire row to the table\n",
    "        table.append(k)\n",
    "    # dom is used as table header. We need it converted to list\n",
    "    dom = list(f['dom'])\n",
    "    # Append a 'Pr' to indicate the probabity column\n",
    "    dom.append('Pr')\n",
    "    print(tabulate(table,headers=dom,tablefmt='orgtbl'))\n",
    "\n",
    "def prob(factor, *entry):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `factor`, a dictionary of domain and probability values,\n",
    "    `entry`, a list of values, one for each variable in the same order as specified in the factor domain.\n",
    "    \n",
    "    Returns p(entry)\n",
    "    \"\"\"\n",
    "\n",
    "    return factor['table'][entry]     # insert your code here, 1 line   \n",
    "\n",
    "def join(f1, f2, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f1`, first factor to be joined.\n",
    "    `f2`, second factor to be joined.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    \n",
    "    Returns a new factor with a join of f1 and f2\n",
    "    \"\"\"\n",
    "    \n",
    "    # First, we need to determine the domain of the new factor. It will be union of the domain in f1 and f2\n",
    "    # But it is important to eliminate the repetitions\n",
    "    common_vars = list(f1['dom']) + list(set(f2['dom']) - set(f1['dom']))\n",
    "    \n",
    "    # We will build a table from scratch, starting with an empty list. Later on, we will transform the list into a odict\n",
    "    table = list()\n",
    "    \n",
    "    # Here is where the magic happens. The product iterator will generate all combinations of varible values \n",
    "    # as specified in outcomeSpace. Therefore, it will naturally respect observed values\n",
    "    for entries in product(*[outcomeSpace[node] for node in common_vars]):\n",
    "        \n",
    "        # We need to map the entries to the domain of the factors f1 and f2\n",
    "        entryDict = dict(zip(common_vars, entries))\n",
    "        f1_entry = (entryDict[var] for var in f1['dom'])\n",
    "        f2_entry = (entryDict[var] for var in f2['dom'])\n",
    "        \n",
    "        # Insert your code here\n",
    "        p1 = prob(f1, *f1_entry)           # Use the fuction prob to calculate the probability in factor f1 for entry f1_entry \n",
    "        p2 = prob(f2, *f2_entry)           # Use the fuction prob to calculate the probability in factor f2 for entry f2_entry \n",
    "        \n",
    "        # Create a new table entry with the multiplication of p1 and p2\n",
    "        table.append((entries, p1 * p2))\n",
    "    return {'dom': tuple(common_vars), 'table': odict(table)}\n",
    "\n",
    "\n",
    "def marginalize(f, var, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, factor to be marginalized.\n",
    "    `var`, variable to be summed out.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    \n",
    "    Returns a new factor f' with dom(f') = dom(f) - {var}\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Let's make a copy of f domain and convert it to a list. We need a list to be able to modify its elements\n",
    "    new_dom = list(f['dom'])\n",
    "    \n",
    "    new_dom.remove(var)            # Remove var from the list new_dom by calling the method remove(). 1 line\n",
    "    table = list()                 # Create an empty list for table. We will fill in table from scratch. 1 line\n",
    "    for entries in product(*[outcomeSpace[node] for node in new_dom]):\n",
    "        s = 0;                     # Initialize the summation variable s. 1 line\n",
    "\n",
    "        # We need to iterate over all possible outcomes of the variable var\n",
    "        for val in outcomeSpace[var]:\n",
    "            # To modify the tuple entries, we will need to convert it to a list\n",
    "            entriesList = list(entries)\n",
    "            # We need to insert the value of var in the right position in entriesList\n",
    "            entriesList.insert(f['dom'].index(var), val)\n",
    "            \n",
    "            p = prob(f, *tuple(entriesList))     # Calculate the probability of factor f for entriesList. 1 line\n",
    "            s = s + p                            # Sum over all values of var by accumulating the sum in s. 1 line\n",
    "            \n",
    "        # Create a new table entry with the multiplication of p1 and p2\n",
    "        table.append((entries, s))\n",
    "    return {'dom': tuple(new_dom), 'table': odict(table)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_trans = {\n",
    "    'dom': ('previous', 'current'), \n",
    "    'table': odict([\n",
    "        (((1,1),), 0.3655),\n",
    "        (((1,0),), 0.6345),\n",
    "        (((0,1),), 0.3344),\n",
    "        (((0,0),), 0.6656),\n",
    "    ])\n",
    "}\n",
    "state_current = {'dom': ('c1',), 'table': odict([((1,), 0.0), ((0,), 1.0)])}\n",
    "\n",
    "prob(c1_trans , (1,1))\n",
    "current_state = {'c1': (0,1)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_have_people(state,trans):\n",
    "    prob_have = prob(trans, (1,1))*state[1] +  prob(trans, (1,0))*state[0] \n",
    "    return (prob_have)\n",
    "\n",
    "def prob_no_people(state,trans):    \n",
    "    prob_no = prob(trans, (0,1))*prob(state,(1)) +  prob(trans, (0,0))*prob(state,(0))\n",
    "    return (prob_no)\n",
    "\n",
    "print(prob_have_people(state_current,c1_trans))\n",
    "print(prob_no_people(state_current,c1_trans))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
