{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP9418 - Assignment 1 - Bayesian Networks as Classifiers\n",
    "\n",
    "## UNSW Sydney, October 2020\n",
    "\n",
    "- Student name 1 - zID\n",
    "- Student name 2 - ZID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "**Submission deadline:** Sunday, 18th October 2020, at 18:00:00.\n",
    "\n",
    "**Late Submission Policy:** The penalty is set at 20% per late day. This is ceiling penalty, so if a group is marked 60/100 and they submitted two days late, they still get 60/100.\n",
    "\n",
    "**Form of Submission:** This is a group assignment. Each group can have up to **two** students. **Only one member of the group should submit the assignment**.\n",
    "\n",
    "You can reuse any piece of source code developed in the tutorials.\n",
    "\n",
    "Submit your files using give. On a CSE Linux machine, type the following on the command-line:\n",
    "\n",
    "``$ give cs9418 ass1 solution.zip``\n",
    "\n",
    "Alternative, you can submit your solution via the [WebCMS](https://webcms3.cse.unsw.edu.au/COMP9418/20T3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical prerequisites\n",
    "\n",
    "These are the libraries your are allowed to use. No other libraries will be accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make division default to floating-point, saving confusion\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Allowed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import heapq as pq\n",
    "import matplotlib as mp\n",
    "import math\n",
    "from itertools import product, combinations\n",
    "from collections import OrderedDict as odict\n",
    "from graphviz import Digraph\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Supplemental libraries\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial task - Initialise graph\n",
    "\n",
    "Create a graph ``G`` that represents the following network by filling in the edge lists.\n",
    "![Bayes Net](BayesNet.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = {\n",
    "    \"BreastDensity\" : [\"Mass\"],\n",
    "    \"Location\" : [\"BC\"],\n",
    "    \"Age\" : [\"BC\"],\n",
    "    \"BC\" : [\"Mass\", \"AD\", \"Metastasis\", \"MC\", \"SkinRetract\",\"NippleDischarge\"],\n",
    "    \"Mass\" : [\"Size\",  \"Shape\", \"Margin\" ],\n",
    "    \"AD\" : [\"FibrTissueDev\"],\n",
    "    \"Metastasis\" : [ \"LymphNodes\"],\n",
    "    \"MC\" : [],\n",
    "    \"Size\" : [],\n",
    "    \"Shape\" : [],\n",
    "    \"FibrTissueDev\" : [ \"SkinRetract\" , \"NippleDischarge\",\"Spiculation\" ],\n",
    "    \"LymphNodes\" : [],\n",
    "    \"SkinRetract\" : [],\n",
    "    \"NippleDischarge\" : [],\n",
    "    \"Spiculation\" : [\"Margin\" ],\n",
    "    \"Margin\" : [],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 Marks] Task 1 - Efficient d-separation test\n",
    "\n",
    "Implement the efficient version of the d-separation algorithm in a function ``d_separation(G, X, Z, Y)`` that return a boolean: true if **X** is d-separated from **Y** given **Z** in the graph $G$ and false otherwise.\n",
    "\n",
    "* **X**,**Y** and **Z** are python sets, each containing a set of variable names. \n",
    "* Variable names may be strings or integers, and can be assumed to be nodes of the graph $G$. \n",
    "* $G$ is a graph as defined in tutorial 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for d_separation(G, X, Z, Y) in one or more cells here\n",
    "import copy \n",
    "\n",
    "\n",
    "def isleaf_node(G,node):\n",
    "    return not G[node] \n",
    "\n",
    "def remove_leaf(G1,leaf_node):\n",
    "    # delete the leaf node and its edges from the G, return a new Graph\n",
    "    G_new = copy.deepcopy(G1)\n",
    "    del G_new[leaf_node]\n",
    "    for key, value in  G_new.items(): \n",
    "        if leaf_node in value:\n",
    "            G_new[key].remove(leaf_node)\n",
    "    return G_new\n",
    "    \n",
    "def repeat_del(G1,node_list): \n",
    "    count = 1 \n",
    "    list_update = node_list.copy()\n",
    "    while count > 0:\n",
    "        count = 0\n",
    "        for node in node_list: \n",
    "            if isleaf_node(G1,node):\n",
    "                #print(node)\n",
    "                #remove the nodes and update the graph \n",
    "                G1= copy.deepcopy(remove_leaf(G1,node))\n",
    "                #print(G)\n",
    "                list_update.remove(node)\n",
    "                count = count + 1 \n",
    "                #print(count)\n",
    "        node_list = list_update.copy()\n",
    "    return (G1)\n",
    "    \n",
    "\n",
    "    #if count == 0:\n",
    "    #    return(G)\n",
    "    #print(list_update)\n",
    "    #new_list = list_update.copy()\n",
    "    #G_new = repeat_del(G,new_list)\n",
    "    \n",
    " \n",
    "    \n",
    "def dfs_r(G, v, colour):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `G`, an adjacency list representation of a graph\n",
    "    `v`, next vertex to be visited\n",
    "    `colour`, dictionary with the colour of each node\n",
    "    \"\"\"\n",
    "    #print('Visiting: ', v)\n",
    "    # Visited vertices are coloured 'grey'\n",
    "    colour[v] = 'grey'\n",
    "    # Let's visit all outgoing edges from v\n",
    "    for w in G[v]:\n",
    "        # To avoid loops, we vist check if the next vertex hasn't been visited yet\n",
    "        if colour[w] == 'white':\n",
    "            dfs_r(G, w, colour)\n",
    "    # When we finish the for loop, we know we have visited all nodes from v. It is time to turn it 'black'\n",
    "    colour[v] = 'black' \n",
    "    return None\n",
    "  \n",
    "\n",
    "\n",
    "def d_separation(G1, X, Z, Y): \n",
    "    \"\"\" \n",
    "    Arguments: \n",
    "    `G`, an adjacency list representation of a graph \n",
    "    `X`, a set of variables name \n",
    "    `Y`, a set of variables name \n",
    "    `Z`, a set of a set of variables name \n",
    "    \n",
    "    Returns \n",
    "    a boolean: true if X is d-separated from Y given Z in the graph  ùê∫  and false otherwise.\n",
    "    \n",
    "    \"\"\"\n",
    "    if bool(X.intersection(Y).intersection(Z)):\n",
    "        print(\"X, Y, Z are not disjoint\")  #make it a warning/ error message? \n",
    "    \n",
    "    combine_set = X.union(Y).union(Z)\n",
    "    node_set = set(G1.keys())\n",
    "    remain_nodes = set(node_set  - combine_set)\n",
    "    \n",
    "    G_final = copy.deepcopy(repeat_del(G1,remain_nodes)) #repeat del leaf nodes \n",
    "    \n",
    "    for var in Z: \n",
    "        G_final[var] = [] #delete outgoing edges from Z set \n",
    "    \n",
    "    for key,values in G_final.items():\n",
    "        if bool(values):\n",
    "            for n in values: \n",
    "                G_final[n].append(key) #make it undirect graph\n",
    "\n",
    "    colour = {node: 'white' for node in G_final.keys()}\n",
    "    #check connectivity \n",
    "    separate = True \n",
    "    for nodex in X:\n",
    "        dfs_r(G_final,nodex,colour) \n",
    "        Y_color = [colour[node] for node in Y]\n",
    "        #print(Y_color)\n",
    "        if 'black' in Y_color:\n",
    "            separate = False\n",
    "            \n",
    "\n",
    "    return(separate)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "def test(statement):\n",
    "    if statement:\n",
    "        print(\"Passed test case\")\n",
    "    else:\n",
    "        print(\"Failed test case\")\n",
    "        \n",
    "test(d_separation(G, set(['Age']), set(['BC']), set(['AD'])))\n",
    "test(not d_separation(G, set(['Spiculation','LymphNodes']), set(['MC', 'Size']), set(['Age'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [10 Marks] Task 2 - Estimate Bayesian Network parameters from data\n",
    "\n",
    "Implement a function ``learn_outcome_space(data)`` that learns the outcome space (the valid values for each variable) from the pandas dataframe ``data`` and returns a dictionary ``outcomeSpace`` with these values.\n",
    "\n",
    "Implement a function ``learn_bayes_net(G, data, outcomeSpace)`` that learns the parameters of the Bayesian Network $G$. This function should return a dictionary ``prob_tables`` with the all conditional probability tables (one for each node).\n",
    "\n",
    "- ``G`` is a directed acyclic graph. For this part of the assignment, $G$ should be declared according to the breast cancer Bayesian network presented in the diagram in the assignment specification.\n",
    "- ``data`` is a dataframe created from a csv file containing the relevant data. \n",
    "- ``outcomeSpace`` is defined in tutorials.\n",
    "- ``prob_tables`` is a dict from each variable name (node) to a \"factor\". Factors are defined in tutorial 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learn_outcome_space(data) in one or more cells here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_outcome_space(data):\n",
    "    outcomeSpace = {}\n",
    "    for attr in data.columns:\n",
    "        outcomeSpace[attr] = tuple(data[attr].unique())\n",
    "    return(outcomeSpace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "with open('bc.csv') as file:\n",
    "    data = pd.read_csv(file)\n",
    "\n",
    "outcomeSpace = learn_outcome_space(data)\n",
    "\n",
    "outcomes = outcomeSpace['BreastDensity']\n",
    "answer = ('high', 'medium', 'low')\n",
    "test(len(outcomes) == len(answer) and set(outcomes) == set(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learn_bayes_net(G, data, outcomeSpace) in one or more cells here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxilliary functions\n",
    "def printFactor(f):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, a factor to print on screen\n",
    "    \"\"\"\n",
    "    # Create a empty list that we will fill in with the probability table entries\n",
    "    table = list()\n",
    "    \n",
    "    # Iterate over all keys and probability values in the table\n",
    "    for key, item in f['table'].items():\n",
    "        # Convert the tuple to a list to be able to manipulate it\n",
    "        k = list(key)\n",
    "        # Append the probability value to the list with key values\n",
    "        k.append(item)\n",
    "        # Append an entire row to the table\n",
    "        table.append(k)\n",
    "    # dom is used as table header. We need it converted to list\n",
    "    dom = list(f['dom'])\n",
    "    # Append a 'Pr' to indicate the probabity column\n",
    "    dom.append('Pr')\n",
    "    print(tabulate(table,headers=dom,tablefmt='fancy_grid'))\n",
    "    \n",
    "def prob(factor, *entry):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `factor`, a dictionary of domain and probability values,\n",
    "    `entry`, a list of values, one for each variable in the same order as specified in the factor domain.\n",
    "    \n",
    "    Returns p(entry)\n",
    "    \"\"\"\n",
    "\n",
    "    return factor['table'][entry]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allEqualThisIndex(dict_of_arrays,**fixed_vars):\n",
    "    first_array = dict_of_arrays[list(dict_of_arrays.keys())[0]]\n",
    "    index = np.ones_like(first_array,dtype=np.bool_)\n",
    "    for var_name,var_val in fixed_vars.items():\n",
    "        index = index & (np.asarray(dict_of_arrays[var_name])==var_val)\n",
    "    return (index)\n",
    "\n",
    "def estProbTable(data,var_name,parent_names,outcomeSpace):\n",
    "    var_outcomes = outcomeSpace[var_name]\n",
    "    parent_outcomes = [outcomeSpace[var] for var in parent_names]\n",
    "    all_parent_combinations = product(*parent_outcomes)\n",
    "    prob_table = odict()\n",
    "    \n",
    "    for i,parent_combination in enumerate(all_parent_combinations):\n",
    "        parent_vars = dict(zip(parent_names,parent_combination))\n",
    "        parent_index = allEqualThisIndex(data,**parent_vars)\n",
    "        for var_outcome in var_outcomes:\n",
    "            var_index = (np.asarray(data[var_name])==var_outcome)\n",
    "            new_dom = tuple(list(parent_combination)+[var_outcome])\n",
    "            prob_table[new_dom]=(var_index & parent_index).sum()/parent_index.sum()\n",
    "    return({'dom':tuple(list(parent_names)+[var_name]),'table':prob_table})\n",
    "\n",
    "def transposeGraph(G):\n",
    "    GT = dict((v,[]) for v in G)\n",
    "    for v in G:\n",
    "        for w in G[v]:\n",
    "            GT[w].append(v)\n",
    "    return (GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_bayes_net(G,data,outcomeSpace):\n",
    "    bayes_net = odict()\n",
    "    GT = transposeGraph(G)\n",
    "    for child, parents in GT.items():\n",
    "        bayes_net[child] = estProbTable(data,child,parents,outcomeSpace)\n",
    "    return(bayes_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "prob_tables = learn_bayes_net(G, data, outcomeSpace)\n",
    "test(abs(prob_tables['Age']['table'][('35-49',)] - 0.2476) < 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 Marks] Task 3 - Bayesian Network Classification\n",
    "\n",
    "Design a new function ``assess_bayes_net(G, prob_tables, data, outcomeSpace, class_var)`` that uses the test cases in ``data`` to assess the performance of the Bayesian network defined by ``G`` and ``prob_tables``. Implement the efficient classification procedure discussed in the lectures. Such a function should return the classifier accuracy. \n",
    " * ``class_var`` is the name of the variable you are predicting, using all other variables.\n",
    " * ``outcomeSpace`` was created in task 2\n",
    " \n",
    "Remember to remove the variables ``metastasis`` and ``lymphnodes`` from the dataset before assessing the accuracy.\n",
    "\n",
    "Return just the accuracy:\n",
    "\n",
    "``acc = assess_bayes_net(G, prob_tables, data, outcomeSpace, class_var)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for assess_bayes_net(G, prob_tables, data, outcomeSpace, class_var) in one or more cells here\n",
    "def join(f1, f2, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f1`, first factor to be joined.\n",
    "    `f2`, second factor to be joined.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    \n",
    "    Returns a new factor with a join of f1 and f2\n",
    "    \"\"\"\n",
    "    \n",
    "    # First, we need to determine the domain of the new factor. It will be union of the domain in f1 and f2\n",
    "    # But it is important to eliminate the repetitions\n",
    "    common_vars = list(f1['dom']) + list(set(f2['dom']) - set(f1['dom']))\n",
    "    \n",
    "    # We will build a table from scratch, starting with an empty list. Later on, we will transform the list into a odict\n",
    "    table = list()\n",
    "    \n",
    "    # Here is where the magic happens. The product iterator will generate all combinations of varible values \n",
    "    # as specified in outcomeSpace. Therefore, it will naturally respect observed values\n",
    "    for entries in product(*[outcomeSpace[node] for node in common_vars]):\n",
    "        \n",
    "        # We need to map the entries to the domain of the factors f1 and f2\n",
    "        entryDict = dict(zip(common_vars, entries))\n",
    "        f1_entry = (entryDict[var] for var in f1['dom'])\n",
    "        f2_entry = (entryDict[var] for var in f2['dom'])\n",
    "        \n",
    "        # Insert your code here\n",
    "        p1 = prob(f1, *f1_entry)           # Use the fuction prob to calculate the probability in factor f1 for entry f1_entry \n",
    "        p2 = prob(f2, *f2_entry)           # Use the fuction prob to calculate the probability in factor f2 for entry f2_entry \n",
    "        \n",
    "        # Create a new table entry with the multiplication of p1 and p2\n",
    "        table.append((entries, p1 * p2))\n",
    "    return {'dom': tuple(common_vars), 'table': odict(table)}\n",
    "\n",
    "def p_joint(outcomeSpace, cond_tables):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `outcomeSpace`, dictionary with domain of each variable\n",
    "    `cond_tables`, conditional probability distributions estimated from data\n",
    "    \n",
    "    Returns a new factor with full joint distribution\n",
    "    \"\"\"    \n",
    "    \n",
    "    var_list = list(outcomeSpace.keys())\n",
    "    p = join(cond_tables[var_list[0]], cond_tables[var_list[1]], outcomeSpace)\n",
    "\n",
    "    for var in var_list[2:]:\n",
    "        p = join(p,cond_tables[var_list[var]],outcomeSpace)\n",
    "\n",
    "    return p\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markov_blanket(G,var):\n",
    "    \"\"\" determine the relevant varaibles given the var of interest, return a list of nodes \"\"\"\n",
    "    blanket_list = []\n",
    "    blanket_list = blanket_list + G[var] #include the children\n",
    "    children_list = blanket_list \n",
    "    GT = transposeGraph(G)\n",
    "    blanket_list = blanket_list + GT[var] #include the parents \n",
    "    \n",
    "    for node in children_list:\n",
    "        blanket_list = blanket_list + GT[node] #include spouse \n",
    "    \n",
    "    blanket_list = list(set(blanket_list))\n",
    "    blanket_list = [i for i in blanket_list if i != var]\n",
    "    return blanket_list\n",
    "    \n",
    "def p_joint_new(my_blanket, outcomeSpace, cond_tables):\n",
    "    var_list = my_blanket\n",
    "    \n",
    "    p = join(cond_tables[var_list[0]], cond_tables[var_list[1]], outcomeSpace)\n",
    "\n",
    "    for var in var_list[2:]:\n",
    "        p = join(p,cond_tables[var], outcomeSpace)\n",
    "\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evidence(var, e, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `var`, a valid variable identifier.\n",
    "    `e`, the observed value for var.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    \n",
    "    Returns dictionary with a copy of outcomeSpace with var = e\n",
    "    \"\"\"    \n",
    "    newOutcomeSpace = outcomeSpace.copy()      # Make a copy of outcomeSpace with a copy to method copy(). 1 line\n",
    "    newOutcomeSpace[var] = (e,)                # Replace the domain of variable var with a tuple with a single element e. 1 line\n",
    "    return newOutcomeSpace\n",
    "\n",
    "def marginalize(f, var, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, factor to be marginalized.\n",
    "    `var`, variable to be summed out.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    \n",
    "    Returns a new factor f' with dom(f') = dom(f) - {var}\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Let's make a copy of f domain and convert it to a list. We need a list to be able to modify its elements\n",
    "    new_dom = list(f['dom'])\n",
    "    \n",
    "    new_dom.remove(var)            # Remove var from the list new_dom by calling the method remove(). 1 line\n",
    "    table = list()                 # Create an empty list for table. We will fill in table from scratch. 1 line\n",
    "    for entries in product(*[outcomeSpace[node] for node in new_dom]):\n",
    "        s = 0;                     # Initialize the summation variable s. 1 line\n",
    "\n",
    "        # We need to iterate over all possible outcomes of the variable var\n",
    "        for val in outcomeSpace[var]:\n",
    "            # To modify the tuple entries, we will need to convert it to a list\n",
    "            entriesList = list(entries)\n",
    "            # We need to insert the value of var in the right position in entriesList\n",
    "            entriesList.insert(f['dom'].index(var), val)\n",
    "                      \n",
    "            p = prob(f, *tuple(entriesList))     # Calculate the probability of factor f for entriesList. 1 line\n",
    "            s = s + p                            # Sum over all values of var by accumulating the sum in s. 1 line\n",
    "            \n",
    "        # Create a new table entry with the multiplication of p1 and p2\n",
    "        table.append((entries, s))\n",
    "    return {'dom': tuple(new_dom), 'table': odict(table)}\n",
    "\n",
    "\n",
    "def normalize(f):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, factor to be normalized.\n",
    "    \n",
    "    Returns a new factor f' as a copy of f with entries that sum up to 1\n",
    "    \"\"\" \n",
    "    table = list()\n",
    "    sum = 0\n",
    "    for k, p in f['table'].items():\n",
    "        sum = sum + p\n",
    "    for k, p in f['table'].items():\n",
    "        table.append((k, p/sum))\n",
    "    return {'dom': f['dom'], 'table': odict(table)}\n",
    "\n",
    "\n",
    "def query(p, outcomeSpace, q_vars, **q_evi):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `p`, probability table to query.\n",
    "    `outcomeSpace`, dictionary will variable domains\n",
    "    `q_vars`, list of variables in query head\n",
    "    `q_evi`, dictionary of evidence in the form of variables names and values\n",
    "    \n",
    "    Returns a new factor NORMALIZED factor will all hidden variables eliminated as evidence set as in q_evi\n",
    "    \"\"\"     \n",
    "    \n",
    "    # Let's make a copy of these structures, since we will reuse the variable names\n",
    "    pm = p.copy()\n",
    "    outSpace = outcomeSpace.copy()\n",
    "    \n",
    "    # First, we set the evidence \n",
    "    for var_evi, e in q_evi.items():\n",
    "        outSpace = evidence(var_evi, e, outSpace)\n",
    "        \n",
    "    # Second, we eliminate hidden variables NOT in the query\n",
    "    for var in outSpace:\n",
    "        if not var in q_vars:\n",
    "            pm = marginalize(pm, var, outSpace)\n",
    "    return normalize(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_bayes_net(G, prob_tables, data, outcomeSpace, class_var):\n",
    "    \n",
    "    var_blanket = markov_blanket(G,class_var)\n",
    "    blanket_without_var = copy.deepcopy(var_blanket)\n",
    "    var_blanket.append(class_var)\n",
    "    var_remove = ['Metastasis', 'LymphNodes']\n",
    "    var_list = [i for i in var_blanket if i not in var_remove] # now we get the variables that needs for inference class_var \n",
    "    \n",
    "    p_table =  p_joint_new(var_list, outcomeSpace, prob_tables)\n",
    "    q_var = class_var\n",
    "    evidence_list = [var for var in var_list if var!=class_var]\n",
    "    data_update = data[evidence_list]\n",
    "    \n",
    "    data_dict = data_update.to_dict(orient='records')\n",
    "    outcomeSpace_copy = { var: outcomeSpace[var] for var in var_list}\n",
    "    match_count = 0\n",
    "    for i in range(len(data_dict)):\n",
    "        q_table = query(p_table, outcomeSpace_copy, q_var, **data_dict[i])\n",
    "        pred = max(q_table['table'],key=q_table['table'].get)[0]\n",
    "        if (pred == data.iloc[i][q_var]):\n",
    "            match_count +=1\n",
    "    return (match_count/data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "class_var = \"BC\"\n",
    "acc = assess_bayes_net(G, prob_tables, data, outcomeSpace, class_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84225"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a function ``cv_bayes_net(G, data, class_var)`` that uses ``learn_outcome_space``, ``learn_bayes_net``and ``assess_bayes_net`` to learn and assess a Bayesian network in a dataset using 10-fold cross-validation. Compute and report the average accuracy over the ten cross-validation runs as well as the standard deviation, e.g.\n",
    "\n",
    "``acc, stddev = cv_bayes_net(G, data, class_var)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for cv_bayes_net(G, data, class_var) in one or more cells here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cross validation is 10 fold here\n",
    "def cv_bayes_net(G,data,class_var):\n",
    "    outcomeSpace = learn_outcome_space(data)\n",
    "    fold_len = int(data.shape[0]/10)\n",
    "    acc_list = []\n",
    "    for i in range(10):\n",
    "        training_index = list(range(0,i*fold_len)) + list(range((i+1)*fold_len,data.shape[0]))\n",
    "        test_index = list(range(i*fold_len,(i+1)*fold_len))\n",
    "        training_data = data.iloc[training_index]\n",
    "        test_data = data.iloc[test_index]\n",
    "        prob_tables = learn_bayes_net(G,training_data,outcomeSpace)\n",
    "        acc_list.append(assess_bayes_net(G,prob_tables,test_data,outcomeSpace,class_var))\n",
    "    \n",
    "    print(acc_list)\n",
    "    return (np.mean(acc_list),np.std(acc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8395, 0.8445, 0.836, 0.8485, 0.846, 0.843, 0.8285, 0.84, 0.837, 0.848]\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "acc, stddev = cv_bayes_net(G, data, 'BC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8411"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [10 Marks] Task 4 - Na√Øve Bayes Classification\n",
    "\n",
    "Design a new function ``assess_naive_bayes(G, prob_tables, data, outcomeSpace, class_var)`` to classify and assess the test cases in a dataset ``data`` according to the Na√Øve Bayes classifier. To classify each example, use the log probability trick discussed in the lectures. This function should return the accuracy of the classifier in ``data``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for assess_naive_bayes(G, prob_tables, data, outcomeSpace, class_var) in one or more cells here\n",
    "\n",
    "def naive_bayes_graph(outcomeSpace, class_var):\n",
    "    \"\"\"Return the naive-bayes graph structure (a dict) according to above info\"\"\"\n",
    "    G_nb = {}\n",
    "    node_list = list(outcomeSpace.keys())\n",
    "    node_list.remove(class_var)\n",
    "    \n",
    "    G_nb[class_var] = node_list\n",
    "    \n",
    "    for nodes in node_list:\n",
    "        G_nb[nodes] = []\n",
    "    \n",
    "    return G_nb\n",
    "\n",
    "\n",
    "def single_var_query( e, node_table):\n",
    "    '''Return the log likelihood for each evidence variable '''\n",
    "    prob_with_evi = {key[0]: value for key,value in node_table['table'].items() if key[1] == e} #np.log avoid error for log(0),, but it is slower\n",
    "    return prob_with_evi\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def predict(x, y_space, table, prior):\n",
    "    pre_dict = {i:  prior[i] for i in y_space}\n",
    "    for i in range(len(x)):\n",
    "        #print(123)\n",
    "        #print(pre_dict)\n",
    "        var_prob = single_var_query(x[i], table[x.index[i]])\n",
    "        #print(234)\n",
    "        #print(var_prob)\n",
    "        for key in pre_dict.keys():\n",
    "            pre_dict[key] = pre_dict[key]* var_prob[key] \n",
    "        \n",
    "    yhat = max(pre_dict, key=pre_dict.get)\n",
    "    \n",
    "    return yhat \n",
    "\n",
    "\n",
    "def assess_naive_bayes(G, prob_tables, data, outcomeSpace, class_var):\n",
    "    G_naive = naive_bayes_graph(outcomeSpace,class_var)\n",
    "    naive_tables = learn_bayes_net(G_naive, data, outcomeSpace)\n",
    "    \n",
    "    node_list = list(outcomeSpace.keys())\n",
    "    var_remove = ['Metastasis', 'LymphNodes']\n",
    "    var_list = [i for i in node_list if i not in var_remove] #now we get all the variables \n",
    "    \n",
    "    evidence_list = [var for var in var_list if var!=class_var]\n",
    "    data_update = data[evidence_list]\n",
    "    \n",
    "    prior_prob = data['BC'].value_counts(normalize = True)\n",
    "    \n",
    "    #p_table =  p_joint_new(var_list, outcomeSpace, naive_tables )\n",
    "    #outcomeSpace_copy = { var: outcomeSpace[var] for var in var_list }\n",
    "    #data_dict = data_update.to_dict(orient='records')\n",
    "    \n",
    "   # prob_dict = {key: [] for key in outcomeSpace[class_var]} #empety dict to store log prob \n",
    "    \n",
    "    \n",
    "    y_hat_series = data_update.apply(predict, y_space = outcomeSpace[class_var], table = naive_tables, prior = prior_prob, axis = 1)\n",
    "    \n",
    "    \n",
    "    ''' y_hat_list = []\n",
    "    \n",
    "    for obs in data_dict:\n",
    "        for var,evidence in obs.items():\n",
    "            single_prob = single_var_query(evidence, naive_tables[var])\n",
    "            for yhat,prob in single_prob.items():\n",
    "                prob_dict[yhat].append(prob) #maybe we should use apply here \n",
    "    \n",
    "        total_prob = {key: sum(value) for key,value in prob_dict.items()}\n",
    "        yhat = max(total_prob)\n",
    "    \n",
    "        y_hat_list.append(yhat)\n",
    "    \n",
    "    y_hat_seires = np.array(y_hat_list)'''\n",
    "\n",
    "    correct_predict = np.sum(data[class_var] == y_hat_series)\n",
    "    acc = correct_predict/len( y_hat_series)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#option 2 use q3 functions \n",
    "def assess_naive_bayes2(G, prob_tables, data, outcomeSpace, class_var):\n",
    "    G_naive = naive_bayes_graph(outcomeSpace,class_var)\n",
    "    naive_tables = learn_bayes_net(G_naive, data, outcomeSpace)\n",
    "    prob = assess_bayes_net(G_naive, naive_tables, data, outcomeSpace, class_var)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "acc = assess_naive_bayes(G, prob_tables, data, outcomeSpace, 'BC')\n",
    "acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7926"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7926"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc2= assess_naive_bayes(G, prob_tables, data, outcomeSpace, 'BC')\n",
    "acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_graph =naive_bayes_graph(outcomeSpace, 'BC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a new function ``cv_naive_bayes(data, class_var)`` that uses ``assess_naive_bayes`` to assess the performance of the Na√Øve Bayes classifier in a dataset ``data``. To develop this code, perform the following steps:\n",
    "\n",
    "1. Use 10-fold cross-validation to split the data into training and test sets.\n",
    "\n",
    "2. Implement a function ``learn_naive_bayes_structure(outcomeSpace, class_var)`` to create and return a Na√Øve Bayes graph structure from ``outcomeSpace`` and ``class_var``. \n",
    "\n",
    "3. Use ``learn_bayes_net(G, data, outcomeSpace)`` to learn the Na√Øve Bayes parameters from a training set ``data``. \n",
    "\n",
    "4. Use ``assess_naive_bayes(G, prob_tables, data, outcomeSpace, class_var)`` to compute the accuracy of the Na√Øve Bayes classifier in a test set ``data``. Remember to remove the variables ``metastasis`` and ``lymphnodes`` from the dataset before assessing the accuracy.\n",
    "\n",
    "Do 10-fold cross-validation, same as above, and return ``acc`` and ``stddev``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learn_naive_bayes_structure(outcomeSpace, class_var) in one or more cells here\n",
    "\n",
    "def learn_naive_bayes_structure(outcomeSpace, class_var):\n",
    "    return naive_bayes_graph(outcomeSpace, class_var)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "naive_graph = learn_naive_bayes_structure(outcomeSpace, 'BC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for cv_naive_bayes(data, class_var) in one or more cells here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "acc, stddev = cv_naive_bayes(data, 'BC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 Marks] Task 5 - Tree-augmented Na√Øve Bayes Classification\n",
    "\n",
    "Similarly to the previous task, implement a Tree-augmented Na√Øve Bayes (TAN) classifier and evaluate your implementation in the breast cancer dataset. Design a function ``learn_tan_structure(data, outcomeSpace, class_var)`` to learn the TAN structure (graph) from the ``data`` and returns such a structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learn_tan_structure(data, outcomeSpace, class_var) in one or more cells here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "tan_graph = learn_tan_structure(data, outcomeSpace, class_var)\n",
    "test(len(tan_graph['BC']) == len(tan_graph)-1)\n",
    "test('FibrTissueDev' in tan_graph['Spiculation'] or 'Spiculation' in tan_graph['FibrTissueDev'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the other tasks, design a function ``cv_tan(data, class_var)`` that uses 10-fold cross-validation to assess the performance of the TAN classifier from ``data``. Remember to remove the variables ``metastasis`` and ``lymphnodes`` from the dataset before assessing the accuracy. This function should use the ``learn_tan_structure`` as well as other functions defined in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for cv_tan(data, class_var) in one or more cells here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "acc, stddev = cv_tan(data, 'BC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 Marks] Task 6 - Report\n",
    "\n",
    "Write a report (**with less than 500 words**) summarising your findings in this assignment. Your report should address the following:\n",
    "\n",
    "a. Make a summary and discussion of the experimental results (accuracy). Use plots to illustrate your results.\n",
    "\n",
    "b. Discuss the complexity of the implemented algorithms.\n",
    "\n",
    "Use Markdown and Latex to write your report in the Jupyter notebook. Develop some plots using Matplotlib to illustrate your results. Be mindful of the maximum number of words. Please, be concise and objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your report in one or more cells here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
